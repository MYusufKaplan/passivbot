# -*- coding: utf-8 -*-

r"""
A Global-best Particle Swarm Optimization (gbest PSO) algorithm.

It takes a set of candidate solutions, and tries to find the best
solution using a position-velocity update method. Uses a
star-topology where each particle is attracted to the best
performing particle.

The position update can be defined as:

.. math::

   x_{i}(t+1) = x_{i}(t) + v_{i}(t+1)

Where the position at the current timestep :math:`t` is updated using
the computed velocity at :math:`t+1`. Furthermore, the velocity update
is defined as:

.. math::

   v_{ij}(t + 1) = w * v_{ij}(t) + c_{1}r_{1j}(t)[y_{ij}(t) âˆ’ x_{ij}(t)]
                   + c_{2}r_{2j}(t)[\hat{y}_{j}(t) âˆ’ x_{ij}(t)]

Here, :math:`c1` and :math:`c2` are the cognitive and social parameters
respectively. They control the particle's behavior given two choices: (1) to
follow its *personal best* or (2) follow the swarm's *global best* position.
Overall, this dictates if the swarm is explorative or exploitative in nature.
In addition, a parameter :math:`w` controls the inertia of the swarm's
movement.

An example usage is as follows:

.. code-block:: python

    import pyswarms as ps
    from pyswarms.utils.functions import single_obj as fx

    # Set-up hyperparameters
    options = {'c1': 0.5, 'c2': 0.3, 'w':0.9}

    # Call instance of GlobalBestPSO
    optimizer = ps.single.GlobalBestPSO(n_particles=10, dimensions=2,
                                        options=options)

    # Perform optimization
    stats = optimizer.optimize(fx.sphere, iters=100)

This algorithm was adapted from the earlier works of J. Kennedy and
R.C. Eberhart in Particle Swarm Optimization [IJCNN1995]_.

.. [IJCNN1995] J. Kennedy and R.C. Eberhart, "Particle Swarm Optimization,"
    Proceedings of the IEEE International Joint Conference on Neural
    Networks, 1995, pp. 1942-1948.
"""

# Import standard library
import logging
import pickle
import os
import time
import datetime
import contextlib
import itertools

# Import modules
import numpy as np
import multiprocessing as mp

from collections import deque

# Advanced initialization imports
try:
    from scipy.stats import qmc
    SCIPY_AVAILABLE = True
except ImportError:
    SCIPY_AVAILABLE = False

# Rich imports for beautiful logging
try:
    from rich.console import Console
    from rich.text import Text
    from rich.panel import Panel
    from rich.rule import Rule
    from rich.progress import Progress, TextColumn, BarColumn, TimeElapsedColumn, TimeRemainingColumn, SpinnerColumn, TaskProgressColumn
    RICH_AVAILABLE = True
except ImportError:
    RICH_AVAILABLE = False

# PCA imports for visualization
try:
    from sklearn.decomposition import PCA
    SKLEARN_AVAILABLE = True
except ImportError:
    SKLEARN_AVAILABLE = False

from ..backend.operators import compute_pbest, compute_objective_function
from ..backend.topology import Star
from ..backend.handlers import BoundaryHandler, VelocityHandler, OptionsHandler
from ..base import SwarmOptimizer
from ..utils.reporter import Reporter
import subprocess

def play_sound(path):
    subprocess.run(["aplay", path], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)

class GlobalBestPSO(SwarmOptimizer):
    def __init__(
        self,
        n_particles,
        dimensions,
        options,
        bounds=None,
        oh_strategy=None,
        bh_strategy="periodic",
        velocity_clamp=None,
        vh_strategy="unmodified",
        center=1.00,
        ftol=-np.inf,
        ftol_iter=1,
        init_pos=None,
        hill_climber_config=None,
    ):
        """Initialize the swarm

        Attributes
        ----------
        n_particles : int
            number of particles in the swarm.
        dimensions : int
            number of dimensions in the space.
        options : dict with keys :code:`{'c1', 'c2', 'w'}`
            a dictionary containing the parameters for the specific
            optimization technique.
                * c1 : float
                    cognitive parameter
                * c2 : float
                    social parameter
                * w : float
                    inertia parameter
        bounds : tuple of numpy.ndarray, optional
            a tuple of size 2 where the first entry is the minimum bound while
            the second entry is the maximum bound. Each array must be of shape
            :code:`(dimensions,)`.
        oh_strategy : dict, optional, default=None(constant options)
            a dict of update strategies for each option.
        bh_strategy : str
            a strategy for the handling of out-of-bounds particles.
        velocity_clamp : tuple, optional
            a tuple of size 2 where the first entry is the minimum velocity and
            the second entry is the maximum velocity. It sets the limits for
            velocity clamping.
        vh_strategy : str
            a strategy for the handling of the velocity of out-of-bounds particles.
        center : list (default is :code:`None`)
            an array of size :code:`dimensions`
        ftol : float
            relative error in objective_func(best_pos) acceptable for
            convergence. Default is :code:`-np.inf`
        ftol_iter : int
            number of iterations over which the relative error in
            objective_func(best_pos) is acceptable for convergence.
            Default is :code:`1`
        init_pos : numpy.ndarray, optional
            option to explicitly set the particles' initial positions. Set to
            :code:`None` if you wish to generate the particles randomly.
        hill_climber_config : dict, optional
            configuration parameters for hill climber functionality. If None,
            uses default configuration. Available parameters:
                * climbers_per_spawn : int
                    number of hill climber particles per spawn (default: 100)
                * hill_climber_lifetime : int
                    lifetime of hill climber groups in iterations (default: 200)
                * ocean_hit_threshold : float
                    percentage threshold for ocean hits to trigger phase transition (default: 0.8)
                * negative_fitness_threshold : float
                    fitness threshold for spawning hill climbers (default: 1e3)
                * ocean_fitness_threshold : float
                    fitness threshold for ocean detection (default: 1e3)
                * initial_radius_percentage : float
                    initial sampling radius as percentage of parameter ranges (default: 0.01)
                * radius_increment_percentage : float
                    radius increment as percentage of parameter ranges (default: 0.01)
                * max_concurrent_groups : int
                    maximum number of concurrent hill climber groups (default: 999)
                * enable_hill_climbers : bool
                    enable/disable hill climber functionality (default: True)
        """
        # Store init_pos for our custom injection logic
        self.custom_init_pos = init_pos
        
        # Pass None to base class to avoid shape conflicts
        super(GlobalBestPSO, self).__init__(
            n_particles=n_particles,
            dimensions=dimensions,
            options=options,
            bounds=bounds,
            velocity_clamp=velocity_clamp,
            center=center,
            ftol=ftol,
            ftol_iter=ftol_iter,
            init_pos=None,  # Always None to avoid base class shape issues
        )

        if oh_strategy is None:
            oh_strategy = {}
        # Initialize logger
        self.rep = Reporter(logger=logging.getLogger(__name__))
        # Initialize the resettable attributes
        self.reset()
        # Initialize the topology
        self.top = Star()
        self.bh = BoundaryHandler(strategy=bh_strategy)
        self.vh = VelocityHandler(strategy=vh_strategy)
        self.oh = OptionsHandler(strategy=oh_strategy)
        self.name = __name__
        
        # Initialize Rich console if available
        if RICH_AVAILABLE:
            self.console = console = Console(
            force_terminal=True, 
            no_color=False, 
            log_path=False, 
            width=191,
            color_system="truecolor",  # Force truecolor support
            legacy_windows=False
        )
        
        # Checkpoint and logging attributes
        self.checkpoint_path = None
        self.checkpoint_interval = 1
        self.generation_times = []
        self.start_time = None
        self.watch_path = "logs/evaluation.log"
        self.graphs_path = "logs/graphs.log"
        self.best_fitness_history = []
        self.stagnation_count = 0
        self.last_improvement_iter = 0
        
        # History data tracking for analysis
        self.history_data_path = "pso_history_data.pkl"
        self.parameter_names = None  # Will be set when bounds are provided
        self.detailed_history = {
            'positions': [],      # All particle positions per iteration
            'fitness_scores': [], # All particle fitness scores per iteration
            'iteration': [],      # Iteration numbers
            'global_best_pos': [],# Global best position per iteration
            'global_best_cost': [],# Global best cost per iteration
            'parameter_names': None # Parameter names for analysis
        }
        
        # Velocity restart mechanism attributes
        self.velocity_threshold = 1e-7  # Threshold for detecting low velocity
        self.restart_fraction = 0.25    # Fraction of particles to restart when velocity is low
        self.low_velocity_count = 0     # Counter for consecutive low velocity iterations
        self.low_velocity_threshold = 5 # Iterations before triggering restart
        
        # Velocity boost attributes
        self.reinit_interval = 10       # Apply velocity boost every X iterations
        self.reinit_fraction = 0.70     # Boost worst Y% of particles
        self.enable_reinit = True       # Enable/disable velocity boost
        
        # Adaptive inertia weight parameters
        self.initial_w = options.get('w', 0.9)
        self.final_w = 0.4
        self.adaptive_inertia = True
        
        # PCA visualization attributes
        self.enable_pca_visualization = True
        self.pca_grid_width = 172   # Fit in 191 char terminal (with panel borders)
        self.pca_grid_height = 31   # Fit in 34 line terminal (with panel borders + legend)
        self.pca = None  # Will be initialized when needed
        
        # Best particle logging
        self.best_log_path = "logs/evaluation_output_best.log"

        # Farthest-point candidate placement configuration
        self.fp_candidate_pool_size = 50000
        self.fp_discovered_cap = 2000
        self.fp_use_sobol = False
        self.fp_dtype = np.float32
        self._discovered_coords = None  # Will be initialized with grid
        
        # Grid-based competitive evolution configuration
        self.competition_enabled = True
        self.max_particles_per_cell = 2
        self.stagnation_window = 15
        self.eviction_percentage = 40  # Percentage of worst particles to evict from stagnant cells
        self.competition_check_interval = 10
        
        # Competition tracking data
        self.visited_cells = set()  # Sparse set of visited grid coordinates
        self.cell_improvement_history = {}  # {grid_coords: [fitness_improvements]}
        self.cell_last_check = {}  # {grid_coords: iteration_number}
        self.global_improvement_history = []  # Track global improvement rate
        self.cell_occupancy = {}  # {grid_coords: [particle_indices]}
        self.cell_fitness_history = {}  # {grid_coords: deque of best fitness values}
        
        # Cell blacklisting system
        self.blacklisted_cells = set()  # Set of blacklisted grid coordinates
        self.blacklist_fitness_threshold = 1e5  # Fitness threshold for blacklisting (10^5)
        self.blacklist_window = 100  # Number of iterations to track for blacklisting
        self.cell_fitness_tracking = {}  # {grid_coords: deque of (iteration, best_fitness) tuples}
        self.cell_stagnation_tracking = {}  # {grid_coords: deque of (iteration, had_improvement) tuples}

        # Hill climber configuration and data structures
        # Set up default configuration values
        default_hill_climber_config = {
            'climbers_per_spawn': 100,
            'hill_climber_lifetime': 200,
            'ocean_hit_threshold': 0.8,
            'negative_fitness_threshold': 1e3,
            'ocean_fitness_threshold': 1e3,
            'initial_radius_percentage': 0.01,
            'radius_increment_percentage': 0.01,
            'max_concurrent_groups': 999,
            'enable_hill_climbers': True
        }
        
        # Merge user-provided config with defaults
        if hill_climber_config is not None:
            # Validate and merge configuration
            self._validate_hill_climber_config(hill_climber_config)
            default_hill_climber_config.update(hill_climber_config)
        
        self.hill_climber_config = default_hill_climber_config
        
        # Initialize hill climber data structures
        self.active_hill_climber_groups = {}  # group_id -> group_data
        self.hill_climber_particles = {}      # particle_id -> particle_data
        self.spawning_history = []            # List of spawning events
        self.attribution_records = []         # List of attribution records
        self._next_group_id = 0               # Counter for generating unique group IDs
        self._next_hill_climber_id = 0        # Counter for generating unique hill climber IDs

    def _validate_hill_climber_config(self, config):
        """Validate hill climber configuration parameters
        
        Parameters
        ----------
        config : dict
            Hill climber configuration dictionary to validate
            
        Raises
        ------
        ValueError
            If any configuration parameter is invalid
        """
        if not isinstance(config, dict):
            raise ValueError("hill_climber_config must be a dictionary")
        
        # Define valid parameters and their validation rules
        valid_params = {
            'climbers_per_spawn': (int, lambda x: x > 0, "must be a positive integer"),
            'hill_climber_lifetime': (int, lambda x: x > 0, "must be a positive integer"),
            'ocean_hit_threshold': ((int, float), lambda x: 0.0 <= x <= 1.0, "must be between 0.0 and 1.0"),
            'negative_fitness_threshold': ((int, float), lambda x: x > 0, "must be positive"),
            'ocean_fitness_threshold': ((int, float), lambda x: x > 0, "must be positive"),
            'initial_radius_percentage': ((int, float), lambda x: 0.0 < x <= 1.0, "must be between 0.0 and 1.0"),
            'radius_increment_percentage': ((int, float), lambda x: 0.0 < x <= 1.0, "must be between 0.0 and 1.0"),
            'max_concurrent_groups': (int, lambda x: x > 0, "must be a positive integer"),
            'enable_hill_climbers': (bool, lambda x: True, "must be a boolean")
        }
        
        # Validate each parameter in the config
        for param_name, param_value in config.items():
            if param_name not in valid_params:
                raise ValueError(f"Unknown hill climber parameter: '{param_name}'")
            
            param_type, validator, error_msg = valid_params[param_name]
            
            # Check type
            if not isinstance(param_value, param_type):
                expected_type = param_type.__name__ if not isinstance(param_type, tuple) else f"one of {[t.__name__ for t in param_type]}"
                raise ValueError(f"Parameter '{param_name}' {error_msg}, got {type(param_value).__name__}")
            
            # Check value constraints
            if not validator(param_value):
                raise ValueError(f"Parameter '{param_name}' {error_msg}, got {param_value}")
        
        # Additional cross-parameter validation
        if 'ocean_hit_threshold' in config and config['ocean_hit_threshold'] == 0.0:
            raise ValueError("ocean_hit_threshold cannot be 0.0 (would never trigger phase transition)")
        
        if ('negative_fitness_threshold' in config and 
            'ocean_fitness_threshold' in config and 
            config['negative_fitness_threshold'] >= config['ocean_fitness_threshold']):
            raise ValueError("negative_fitness_threshold must be less than ocean_fitness_threshold")

    def set_checkpoint_config(self, checkpoint_path="pso_checkpoint.pkl", checkpoint_interval=5, watch_path="logs/evaluation.log"):
        """Configure checkpoint and logging settings"""
        self.checkpoint_path = checkpoint_path
        self.checkpoint_interval = checkpoint_interval
        self.watch_path = watch_path

    def set_history_config(self, history_data_path="pso_history_data.pkl", parameter_names=None):
        """Configure history data collection for analysis
        
        Parameters
        ----------
        history_data_path : str
            Path to save detailed history data for analysis
        parameter_names : list of str, optional
            Names of the parameters being optimized (for analysis readability)
        """
        self.history_data_path = history_data_path
        self.parameter_names = parameter_names
        if parameter_names:
            self.detailed_history['parameter_names'] = parameter_names
        self.log_message(f"ğŸ“ˆ History data will be saved to: {history_data_path}", emoji="ğŸ“ˆ")

    def save_history_data(self, iteration):
        """Save detailed history data for analysis (append mode)"""
        if not self.history_data_path:
            return
            
        try:
            # Load existing history if file exists and we haven't loaded it yet
            if os.path.exists(self.history_data_path) and not hasattr(self, '_history_loaded'):
                try:
                    with open(self.history_data_path, "rb") as f:
                        existing_data = pickle.load(f)
                    
                    # Merge existing data with current structure
                    for key in ['iteration', 'positions', 'fitness_scores', 'global_best_pos', 'global_best_cost']:
                        if key in existing_data and existing_data[key]:
                            self.detailed_history[key].extend(existing_data[key])
                    
                    # Preserve parameter names from existing data if available
                    if existing_data.get('parameter_names') and not self.detailed_history.get('parameter_names'):
                        self.detailed_history['parameter_names'] = existing_data['parameter_names']
                    
                    self._history_loaded = True
                    existing_count = len(existing_data.get('iteration', []))
                    if existing_count > 0:
                        self.log_message(f"ğŸ“š Loaded {existing_count} existing history records", emoji="ğŸ“š")
                        
                except Exception as e:
                    self.log_message(f"âš ï¸ Could not load existing history: {e}, starting fresh", emoji="âš ï¸")
                    self._history_loaded = True  # Mark as attempted to avoid repeated tries
            
            # Store current iteration data (append to existing)
            self.detailed_history['iteration'].append(iteration)
            self.detailed_history['positions'].append(self.swarm.position.copy())
            self.detailed_history['fitness_scores'].append(self.swarm.current_cost.copy())
            self.detailed_history['global_best_pos'].append(self.swarm.best_pos.copy())
            self.detailed_history['global_best_cost'].append(self.swarm.best_cost)
            
            # Save complete history to file
            with open(self.history_data_path, "wb") as f:
                pickle.dump(self.detailed_history, f)
            
            # Log progress every 10 iterations to avoid spam
            if iteration % 10 == 0:
                total_records = len(self.detailed_history['iteration'])
                self.log_message(f"ğŸ“Š History data saved (iteration {iteration}, total records: {total_records})", emoji="ğŸ“Š")
                
        except Exception as e:
            self.log_message(f"âš ï¸ Failed to save history data: {e}", emoji="âš ï¸")

    def console_wrapper(self, msg):
        """Wrapper for Rich console output with file logging"""
        if RICH_AVAILABLE and hasattr(self, 'console'):
            with open(self.watch_path, "a") as f, contextlib.redirect_stdout(f), contextlib.redirect_stderr(f):
                self.console.print(msg)

    def log_message(self, message, emoji=None, panel=False, timestamp=True):
        """Utility function to print logs with Rich panels and rules"""
        if not RICH_AVAILABLE:
            print(f"{emoji} {message}" if emoji else message)
            return
            
        if timestamp:
            timestamp_str = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        else:
            timestamp_str = ""
        emoji_str = f" {emoji}" if emoji else ""
        log_text = f"{timestamp_str}{emoji_str} {message}"

        # Using Rule for major transitions
        if panel:
            panel_message = Panel(log_text, title="PSO Stats", border_style="cyan")
            self.console_wrapper(panel_message)
        else:
            self.console_wrapper(log_text)

    def save_checkpoint(self, iteration, additional_data=None):
        """Save PSO state to checkpoint file"""
        if not self.checkpoint_path:
            return
            
        checkpoint_data = {
            "iteration": iteration,
            "swarm_position": self.swarm.position,
            "swarm_velocity": self.swarm.velocity,
            "swarm_pbest_pos": self.swarm.pbest_pos,
            "swarm_pbest_cost": self.swarm.pbest_cost,
            "swarm_best_pos": self.swarm.best_pos,
            "swarm_best_cost": self.swarm.best_cost,
            "cost_history": self.cost_history,
            "pos_history": self.pos_history,
            "options": self.options,
            "bounds": self.bounds,
            "generation_times": self.generation_times,
            "best_fitness_history": self.best_fitness_history,
            "stagnation_count": self.stagnation_count,
            "last_improvement_iter": self.last_improvement_iter,
            # Sparse exploration tracking is saved via competitive evolution data
            # Save competitive evolution data (checkpoint-friendly sparse format)
            "visited_cells": getattr(self, 'visited_cells', set()),
            "global_improvement_history": getattr(self, 'global_improvement_history', []),
            "cell_fitness_history": getattr(self, 'cell_fitness_history', {}),
            # Save blacklist data
            "blacklisted_cells": getattr(self, 'blacklisted_cells', set()),
            "cell_fitness_tracking": getattr(self, 'cell_fitness_tracking', {}),
            "cell_stagnation_tracking": getattr(self, 'cell_stagnation_tracking', {}),
        }
        
        if additional_data:
            checkpoint_data.update(additional_data)
        
        try:
            with open(self.checkpoint_path, "wb") as f:
                pickle.dump(checkpoint_data, f)
            self.log_message(f"ğŸ’¾ PSO checkpoint saved at iteration {iteration}", emoji="ğŸ’¾")
        except Exception as e:
            self.log_message(f"âš ï¸ Failed to save checkpoint: {e}", emoji="âš ï¸")

    def load_checkpoint(self):
        """Load PSO state from checkpoint file with dynamic particle count support"""
        if not self.checkpoint_path or not os.path.exists(self.checkpoint_path):
            return None
            
        try:
            with open(self.checkpoint_path, "rb") as f:
                checkpoint_data = pickle.load(f)
            
            # Get checkpoint swarm size
            checkpoint_n_particles = checkpoint_data["swarm_position"].shape[0]
            current_n_particles = self.n_particles
            
            # Restore global best state (always preserved)
            self.swarm.best_pos = checkpoint_data["swarm_best_pos"]
            self.swarm.best_cost = checkpoint_data["swarm_best_cost"]
            
            # Handle particle count changes
            if checkpoint_n_particles == current_n_particles:
                # Same size - direct restore
                self.swarm.position = checkpoint_data["swarm_position"]
                self.swarm.velocity = checkpoint_data["swarm_velocity"]
                self.swarm.pbest_pos = checkpoint_data["swarm_pbest_pos"]
                self.swarm.pbest_cost = checkpoint_data["swarm_pbest_cost"]
                self.log_message(f"âœ… Resumed with same swarm size ({current_n_particles} particles)", emoji="âœ…")
                
            elif checkpoint_n_particles > current_n_particles:
                # Shrinking swarm - keep best particles
                checkpoint_pbest_cost = checkpoint_data["swarm_pbest_cost"]
                best_indices = np.argsort(checkpoint_pbest_cost)[:current_n_particles]
                
                self.swarm.position = checkpoint_data["swarm_position"][best_indices]
                self.swarm.velocity = checkpoint_data["swarm_velocity"][best_indices]
                self.swarm.pbest_pos = checkpoint_data["swarm_pbest_pos"][best_indices]
                self.swarm.pbest_cost = checkpoint_data["swarm_pbest_cost"][best_indices]
                
                self.log_message(f"ğŸ“‰ Shrunk swarm from {checkpoint_n_particles} to {current_n_particles} particles (kept best performers)", emoji="ğŸ“‰")
                
            else:
                # Growing swarm - preserve existing + add new particles
                self.swarm.position = np.zeros((current_n_particles, self.dimensions))
                self.swarm.velocity = np.zeros((current_n_particles, self.dimensions))
                self.swarm.pbest_pos = np.zeros((current_n_particles, self.dimensions))
                self.swarm.pbest_cost = np.full(current_n_particles, np.inf)
                
                # Copy existing particles
                self.swarm.position[:checkpoint_n_particles] = checkpoint_data["swarm_position"]
                self.swarm.velocity[:checkpoint_n_particles] = checkpoint_data["swarm_velocity"]
                self.swarm.pbest_pos[:checkpoint_n_particles] = checkpoint_data["swarm_pbest_pos"]
                self.swarm.pbest_cost[:checkpoint_n_particles] = checkpoint_data["swarm_pbest_cost"]
                
                # Initialize new particles
                new_particles = current_n_particles - checkpoint_n_particles
                
                # Initialize positions for new particles
                if self.bounds is not None:
                    min_bounds, max_bounds = self.bounds
                    self.swarm.position[checkpoint_n_particles:] = np.random.uniform(
                        min_bounds, max_bounds, (new_particles, self.dimensions)
                    )
                else:
                    # Use center-based initialization if no bounds
                    self.swarm.position[checkpoint_n_particles:] = np.random.uniform(
                        -1, 1, (new_particles, self.dimensions)
                    ) * self.center
                
                # Initialize velocities for new particles
                if self.velocity_clamp is not None:
                    min_vel, max_vel = self.velocity_clamp
                    self.swarm.velocity[checkpoint_n_particles:] = np.random.uniform(
                        min_vel, max_vel, (new_particles, self.dimensions)
                    )
                else:
                    # Default velocity initialization
                    if self.bounds is not None:
                        min_bounds, max_bounds = self.bounds
                        vel_range = 0.1 * (max_bounds - min_bounds)
                        self.swarm.velocity[checkpoint_n_particles:] = np.random.uniform(
                            -vel_range, vel_range, (new_particles, self.dimensions)
                        )
                    else:
                        self.swarm.velocity[checkpoint_n_particles:] = np.random.uniform(
                            -0.1, 0.1, (new_particles, self.dimensions)
                        )
                
                # Initialize pbest for new particles (will be set properly in first iteration)
                self.swarm.pbest_pos[checkpoint_n_particles:] = self.swarm.position[checkpoint_n_particles:]
                
                self.log_message(f"ğŸ“ˆ Expanded swarm from {checkpoint_n_particles} to {current_n_particles} particles (added {new_particles} new particles)", emoji="ğŸ“ˆ")
            
            # Restore other state variables
            self.cost_history = checkpoint_data.get("cost_history", [])
            self.pos_history = checkpoint_data.get("pos_history", [])
            self.generation_times = checkpoint_data.get("generation_times", [])
            self.best_fitness_history = checkpoint_data.get("best_fitness_history", [])
            self.stagnation_count = checkpoint_data.get("stagnation_count", 0)
            self.last_improvement_iter = checkpoint_data.get("last_improvement_iter", 0)
            
            # Restore exploration tracking data (backwards compatible)
            if "visited_grid" in checkpoint_data and checkpoint_data["visited_grid"] is not None:
                # Convert old dense grid to sparse format
                old_visited_grid = checkpoint_data["visited_grid"]
                self.grid_resolution = checkpoint_data.get("grid_resolution", None)
                self._total_grid_cells = checkpoint_data.get("total_grid_cells", None)
                
                # Convert dense grid to sparse visited_cells set
                if not hasattr(self, 'visited_cells'):
                    self.visited_cells = set()
                
                for coords in np.ndindex(old_visited_grid.shape):
                    if old_visited_grid[coords]:
                        self.visited_cells.add(coords)
                
                visited_count = len(self.visited_cells)
                self.log_message(f"ğŸ—ºï¸ Converted old dense grid to sparse format: {visited_count:,} cells visited", emoji="ğŸ—ºï¸")
            else:
                # Backwards compatibility - no exploration data in old checkpoints
                self.log_message("ğŸ—ºï¸ No exploration data in checkpoint - will initialize fresh sparse grid", emoji="ğŸ—ºï¸")
            
            # Restore competitive evolution data (backwards compatible)
            self.visited_cells = checkpoint_data.get("visited_cells", set())
            self.global_improvement_history = checkpoint_data.get("global_improvement_history", [])
            self.cell_fitness_history = checkpoint_data.get("cell_fitness_history", {})
            
            # Convert cell_fitness_history back to deques with proper maxlen
            for grid_coords in self.cell_fitness_history:
                fitness_list = self.cell_fitness_history[grid_coords]
                self.cell_fitness_history[grid_coords] = deque(fitness_list, maxlen=self.stagnation_window)
            
            # Restore blacklist data (backwards compatible)
            self.blacklisted_cells = checkpoint_data.get("blacklisted_cells", set())
            self.cell_fitness_tracking = checkpoint_data.get("cell_fitness_tracking", {})
            self.cell_stagnation_tracking = checkpoint_data.get("cell_stagnation_tracking", {})
            
            # Convert blacklist tracking back to deques with proper maxlen
            for grid_coords in self.cell_fitness_tracking:
                tracking_list = self.cell_fitness_tracking[grid_coords]
                self.cell_fitness_tracking[grid_coords] = deque(tracking_list, maxlen=self.blacklist_window)
            
            for grid_coords in self.cell_stagnation_tracking:
                tracking_list = self.cell_stagnation_tracking[grid_coords]
                self.cell_stagnation_tracking[grid_coords] = deque(tracking_list, maxlen=self.blacklist_window)
            
            if self.visited_cells:
                self.log_message(f"âš”ï¸ Restored competitive evolution: {len(self.visited_cells):,} visited cells", emoji="âš”ï¸")
            
            if self.blacklisted_cells:
                self.log_message(f"ğŸš« Restored blacklist: {len(self.blacklisted_cells):,} blacklisted cells", emoji="ğŸš«")
            
            start_iter = checkpoint_data["iteration"] + 1
            self.log_message(f"âœ… Resumed from iteration {checkpoint_data['iteration']}, best fitness: {self.swarm.best_cost:.6e}", emoji="âœ…")
            return start_iter
            
        except Exception as e:
            self.log_message(f"âš ï¸ Failed to load checkpoint: {e}, starting fresh", emoji="âš ï¸")
            return None

    def _generate_latin_hypercube_positions(self, n_particles, bounds):
        """Generate initial positions using Latin Hypercube Sampling for better space coverage"""
        if not SCIPY_AVAILABLE:
            self.log_message("âš ï¸ SciPy not available, falling back to uniform random initialization", emoji="âš ï¸")
            return self._generate_uniform_positions(n_particles, bounds)
        
        try:
            sampler = qmc.LatinHypercube(d=self.dimensions, seed=np.random.randint(0, 2**31))
            sample = sampler.random(n=n_particles)
            
            if bounds is not None:
                lower_bounds, upper_bounds = bounds
                positions = qmc.scale(sample, lower_bounds, upper_bounds)
            else:
                # Scale to [-center, center] if no bounds
                positions = qmc.scale(sample, -self.center, self.center)
            
            # self.log_message(f"ğŸ¯ Initialized {n_particles} particles using Latin Hypercube Sampling", emoji="ğŸ¯")
            return positions
            
        except Exception as e:
            self.log_message(f"âš ï¸ LHS initialization failed: {e}, falling back to uniform", emoji="âš ï¸")
            return self._generate_uniform_positions(n_particles, bounds)

    def _generate_sobol_positions(self, n_particles, bounds):
        """Generate initial positions using Sobol sequences for low-discrepancy coverage"""
        if not SCIPY_AVAILABLE:
            self.log_message("âš ï¸ SciPy not available, falling back to uniform random initialization", emoji="âš ï¸")
            return self._generate_uniform_positions(n_particles, bounds)
        
        try:
            sampler = qmc.Sobol(d=self.dimensions, scramble=True, seed=np.random.randint(0, 2**31))
            # Generate next power of 2 >= n_particles for Sobol efficiency
            n_sobol = 2**int(np.ceil(np.log2(n_particles)))
            sample = sampler.random(n=n_sobol)
            
            # Take only the particles we need
            sample = sample[:n_particles]
            
            if bounds is not None:
                lower_bounds, upper_bounds = bounds
                positions = qmc.scale(sample, lower_bounds, upper_bounds)
            else:
                positions = qmc.scale(sample, -self.center, self.center)
            
            self.log_message(f"ğŸŒ Initialized {n_particles} particles using Sobol sequences", emoji="ğŸŒ")
            return positions
            
        except Exception as e:
            self.log_message(f"âš ï¸ Sobol initialization failed: {e}, falling back to uniform", emoji="âš ï¸")
            return self._generate_uniform_positions(n_particles, bounds)

    def _generate_stratified_positions(self, n_particles, bounds):
        """Generate positions using stratified sampling - divide each dimension into equal segments"""
        try:
            if bounds is None:
                lower_bounds = np.full(self.dimensions, -self.center)
                upper_bounds = np.full(self.dimensions, self.center)
            else:
                lower_bounds, upper_bounds = bounds
            
            positions = np.zeros((n_particles, self.dimensions))
            
            # For each dimension, create stratified samples
            for dim in range(self.dimensions):
                # Divide the dimension into n_particles equal segments
                segments = np.linspace(lower_bounds[dim], upper_bounds[dim], n_particles + 1)
                
                # Sample randomly within each segment
                for i in range(n_particles):
                    positions[i, dim] = np.random.uniform(segments[i], segments[i + 1])
            
            # Shuffle particles to avoid correlation between dimensions
            np.random.shuffle(positions)
            
            self.log_message(f"ğŸ“Š Initialized {n_particles} particles using stratified sampling", emoji="ğŸ“Š")
            return positions
            
        except Exception as e:
            self.log_message(f"âš ï¸ Stratified initialization failed: {e}, falling back to uniform", emoji="âš ï¸")
            return self._generate_uniform_positions(n_particles, bounds)

    def _generate_opposition_based_positions(self, n_particles, bounds):
        """Generate positions using Opposition-Based Learning - for each random particle, create its opposite"""
        try:
            if bounds is None:
                lower_bounds = np.full(self.dimensions, -self.center)
                upper_bounds = np.full(self.dimensions, self.center)
            else:
                lower_bounds, upper_bounds = bounds
            
            # Generate half the particles randomly
            half_particles = n_particles // 2
            random_positions = np.random.uniform(lower_bounds, upper_bounds, (half_particles, self.dimensions))
            
            # Generate opposite positions: opposite = lower + upper - original
            opposite_positions = lower_bounds + upper_bounds - random_positions
            
            # Combine random and opposite positions
            if n_particles % 2 == 0:
                positions = np.vstack([random_positions, opposite_positions])
            else:
                # Add one more random particle if odd number
                extra_particle = np.random.uniform(lower_bounds, upper_bounds, (1, self.dimensions))
                positions = np.vstack([random_positions, opposite_positions, extra_particle])
            
            # Shuffle to mix random and opposite particles
            np.random.shuffle(positions)
            
            self.log_message(f"ğŸ”„ Initialized {n_particles} particles using Opposition-Based Learning", emoji="ğŸ”„")
            return positions
            
        except Exception as e:
            self.log_message(f"âš ï¸ Opposition-based initialization failed: {e}, falling back to uniform", emoji="âš ï¸")
            return self._generate_uniform_positions(n_particles, bounds)

    def _generate_hybrid_positions(self, n_particles, bounds):
        """Generate positions using a hybrid approach combining multiple initialization strategies"""
        try:
            # Divide particles among different strategies
            n_lhs = n_particles // 4
            n_sobol = n_particles // 4  
            n_stratified = n_particles // 4
            n_opposition = n_particles - n_lhs - n_sobol - n_stratified  # Remainder
            
            positions_list = []
            
            # Latin Hypercube Sampling
            if n_lhs > 0:
                lhs_pos = self._generate_latin_hypercube_positions(n_lhs, bounds)
                positions_list.append(lhs_pos)
            
            # Sobol sequences
            if n_sobol > 0:
                sobol_pos = self._generate_sobol_positions(n_sobol, bounds)
                positions_list.append(sobol_pos)
            
            # Stratified sampling
            if n_stratified > 0:
                strat_pos = self._generate_stratified_positions(n_stratified, bounds)
                positions_list.append(strat_pos)
            
            # Opposition-based learning
            if n_opposition > 0:
                opp_pos = self._generate_opposition_based_positions(n_opposition, bounds)
                positions_list.append(opp_pos)
            
            # Combine all positions
            positions = np.vstack(positions_list)
            
            # Shuffle to mix different initialization strategies
            np.random.shuffle(positions)
            
            self.log_message(f"ğŸ­ Initialized {n_particles} particles using hybrid approach (LHS:{n_lhs}, Sobol:{n_sobol}, Stratified:{n_stratified}, Opposition:{n_opposition})", emoji="ğŸ­")
            return positions
            
        except Exception as e:
            self.log_message(f"âš ï¸ Hybrid initialization failed: {e}, falling back to uniform", emoji="âš ï¸")
            return self._generate_uniform_positions(n_particles, bounds)

    def _generate_uniform_positions(self, n_particles, bounds):
        """Generate positions using uniform random sampling (fallback method)"""
        if bounds is None:
            positions = np.random.uniform(-self.center, self.center, (n_particles, self.dimensions))
        else:
            lower_bounds, upper_bounds = bounds
            positions = np.random.uniform(lower_bounds, upper_bounds, (n_particles, self.dimensions))
        
        self.log_message(f"ğŸ² Initialized {n_particles} particles using uniform random sampling", emoji="ğŸ²")
        return positions

    def _handle_history_on_reevaluation(self, old_global_best, new_global_best):
        """Handle history data when objective function may have changed during checkpoint resume
        
        Parameters
        ----------
        old_global_best : float
            Global best fitness before reevaluation
        new_global_best : float
            Global best fitness after reevaluation
        """
        # Calculate the magnitude of change
        change_magnitude = abs(new_global_best - old_global_best)
        relative_change = change_magnitude / (abs(old_global_best) + 1e-10)  # Avoid division by zero
        
        # Determine if the change is significant enough to warrant history clearing
        significant_change_threshold = getattr(self, 'significant_change_threshold', 0.01)  # 1% relative change
        
        if relative_change > significant_change_threshold:
            # Significant change detected - clear potentially outdated history
            self.log_message(f"âš ï¸ Significant fitness change detected ({relative_change:.2%}), clearing potentially outdated history", emoji="âš ï¸")
            
            # Clear internal PSO history (cost_history, pos_history)
            self.cost_history = []
            self.pos_history = []
            self.best_fitness_history = []
            
            # Clear detailed history for analysis
            self.detailed_history = {
                'positions': [],
                'fitness_scores': [],
                'iteration': [],
                'global_best_pos': [],
                'global_best_cost': [],
                'parameter_names': self.detailed_history.get('parameter_names')  # Preserve parameter names
            }
            
            # Clear the history file to start fresh
            if self.history_data_path and os.path.exists(self.history_data_path):
                try:
                    os.remove(self.history_data_path)
                    self.log_message(f"ğŸ—‘ï¸ Cleared history file: {self.history_data_path}", emoji="ğŸ—‘ï¸")
                except Exception as e:
                    self.log_message(f"âš ï¸ Failed to clear history file: {e}", emoji="âš ï¸")
            
            # Reset history loading flag
            if hasattr(self, '_history_loaded'):
                delattr(self, '_history_loaded')
            
            self.log_message("ğŸ”„ History cleared due to objective function changes - starting fresh tracking", emoji="ğŸ”„")
        else:
            # Minor change - keep history but add a note
            self.log_message(f"âœ… Minor fitness change ({relative_change:.2%}), keeping existing history", emoji="âœ…")

    def set_history_clear_threshold(self, threshold=0.01):
        """Set the threshold for clearing history when objective function changes
        
        Parameters
        ----------
        threshold : float
            Relative change threshold (default: 0.01 = 1%)
            If the relative change in global best fitness exceeds this threshold
            when resuming from checkpoint, history will be cleared
        """
        self.significant_change_threshold = threshold
        self.log_message(f"ğŸ“Š Set history clear threshold to {threshold:.2%}", emoji="ğŸ“Š")

    def set_grid_resolution(self, resolution=None):
        """Set the grid resolution for search space exploration tracking
        
        Parameters
        ----------
        resolution : int, optional
            Number of bins per dimension for the exploration grid.
            If None, uses adaptive resolution based on problem dimensions.
            Higher values give more precise tracking but use more memory.
        """
        if resolution is not None:
            self.grid_resolution = resolution
            # Clear existing sparse grid to use new resolution
            self.visited_cells.clear()
            self._total_grid_cells = resolution ** self.dimensions
            self.log_message(f"ğŸ”¢ Set sparse grid resolution to {resolution}^{self.dimensions} = {resolution**self.dimensions:,} cells", emoji="ğŸ”¢")
        else:
            self.log_message("ğŸ”¢ Using adaptive sparse grid resolution based on problem dimensions", emoji="ğŸ”¢")

    def reset_exploration_tracking(self):
        """Reset the sparse exploration grid to start fresh tracking"""
        self.visited_cells.clear()
        if hasattr(self, '_discovered_coords'):
            self._discovered_coords.clear()
        self.log_message("ğŸ”„ Reset sparse exploration tracking grid", emoji="ğŸ”„")

    def set_pca_visualization(self, enable=True, width=150, height=25, graphs_path="logs/graphs.log"):
        """Configure PCA visualization settings
        
        Parameters
        ----------
        enable : bool
            Enable/disable PCA visualization (default: True)
        width : int
            Width of the ASCII grid in characters (default: 140 for 159-char terminal)
        height : int
            Height of the ASCII grid in lines (default: 25 for 34-line terminal)
        graphs_path : str
            Path to write visualization graphs (default: "logs/graphs.log")
        """
        self.enable_pca_visualization = enable
        self.pca_grid_width = width
        self.pca_grid_height = height
        self.graphs_path = graphs_path
        self.log_message(f"ğŸ“Š PCA visualization: {'enabled' if enable else 'disabled'} (grid: {width}x{height})", emoji="ğŸ“Š")

    def _create_pca_visualization(self, iteration):
        """Create PCA-based ASCII visualization of particle distribution"""
        if not self.enable_pca_visualization or not RICH_AVAILABLE or not SKLEARN_AVAILABLE:
            if not SKLEARN_AVAILABLE and iteration == 0:  # Only warn once
                self.log_message("âš ï¸ sklearn not available, PCA visualization disabled", emoji="âš ï¸")
            return
        
        # Get current particle positions
        positions = self.swarm.position
        
        if positions.shape[0] < 2 or positions.shape[1] < 2:
            return  # Need at least 2 particles and 2 dimensions
        
        # Fit PCA if not already done or refit periodically
        if self.pca is None or iteration % 10 == 0:  # Refit every 10 iterations
            self.pca = PCA(n_components=2)
            self.pca.fit(positions)
        
        # Transform positions to 2D
        positions_2d = self.pca.transform(positions)
        
        # Also transform personal best positions for more comprehensive view
        pbest_2d = self.pca.transform(self.swarm.pbest_pos)
        
        # Find global best position in 2D
        global_best_idx = np.argmin(self.swarm.pbest_cost)
        global_best_2d = pbest_2d[global_best_idx]
        
        # Create ASCII grid
        grid_width = self.pca_grid_width
        grid_height = self.pca_grid_height
        density_grid = np.zeros((grid_height, grid_width))
        
        # Combine current and personal best positions for density calculation
        all_positions_2d = np.vstack([positions_2d, pbest_2d])
        
        # Find bounds for the grid
        min_x, max_x = np.min(all_positions_2d[:, 0]), np.max(all_positions_2d[:, 0])
        min_y, max_y = np.min(all_positions_2d[:, 1]), np.max(all_positions_2d[:, 1])
        
        # Add padding to avoid edge effects
        padding_x = (max_x - min_x) * 0.1
        padding_y = (max_y - min_y) * 0.1
        min_x -= padding_x
        max_x += padding_x
        min_y -= padding_y
        max_y += padding_y
        
        # Map positions to grid indices
        if max_x > min_x and max_y > min_y:
            for pos in all_positions_2d:
                grid_x = int((pos[0] - min_x) / (max_x - min_x) * (grid_width - 1))
                grid_y = int((pos[1] - min_y) / (max_y - min_y) * (grid_height - 1))
                grid_x = max(0, min(grid_x, grid_width - 1))
                grid_y = max(0, min(grid_y, grid_height - 1))
                density_grid[grid_y, grid_x] += 1
        
        # Find global best position in grid
        if max_x > min_x and max_y > min_y:
            best_grid_x = int((global_best_2d[0] - min_x) / (max_x - min_x) * (grid_width - 1))
            best_grid_y = int((global_best_2d[1] - min_y) / (max_y - min_y) * (grid_height - 1))
            best_grid_x = max(0, min(best_grid_x, grid_width - 1))
            best_grid_y = max(0, min(best_grid_y, grid_height - 1))
        else:
            best_grid_x = grid_width // 2
            best_grid_y = grid_height // 2
        
        # Convert density to Rich colored characters (10 levels + empty + global best)
        max_density = np.max(density_grid) if np.max(density_grid) > 0 else 1
        
        # 10-level color gradient from cold (low density) to hot (high density)
        # Using Rich color styling with single characters for perfect alignment
        from rich.text import Text
        
        def get_colored_char(level):
            if level == 0:
                return Text("Â·", style="dim black")  # Empty
            elif level == 1:
                return Text("â–ª", style="blue")       # Coldest
            elif level == 2:
                return Text("â–ª", style="bright_blue")
            elif level == 3:
                return Text("â–ª", style="cyan")
            elif level == 4:
                return Text("â–ª", style="bright_cyan")
            elif level == 5:
                return Text("â–ª", style="green")
            elif level == 6:
                return Text("â–ª", style="bright_green")
            elif level == 7:
                return Text("â–ª", style="yellow")
            elif level == 8:
                return Text("â–ª", style="bright_yellow")
            elif level == 9:
                return Text("â–ª", style="red")
            else:  # level 10
                return Text("â–ª", style="bright_red")  # Hottest
        
        # Return the style string for a given level so we can color '@' similarly
        def get_style_for_level(level):
            if level == 0:
                return "dim black"
            elif level == 1:
                return "blue"
            elif level == 2:
                return "bright_blue"
            elif level == 3:
                return "cyan"
            elif level == 4:
                return "bright_cyan"
            elif level == 5:
                return "green"
            elif level == 6:
                return "bright_green"
            elif level == 7:
                return "yellow"
            elif level == 8:
                return "bright_yellow"
            elif level == 9:
                return "red"
            else:
                return "bright_red"
        
        # Create the visualization
        lines = []
        
        # Add compact header with axis labels (every 20 chars for readability)
        header = "    " + "".join([f"{i:2d}" if i % 20 == 0 else "  " for i in range(0, grid_width, 2)])
        lines.append(header[:grid_width + 4])  # Truncate if too long
        
        # Build the grid using Rich Text objects for proper coloring
        grid_lines = []
        for y in range(grid_height):
            line_text = Text(f"{y:2d} ")
            for x in range(grid_width):
                if x == best_grid_x and y == best_grid_y:
                    density = density_grid[y, x]
                    if density == 0:
                        char_level = 0
                    else:
                        if max_density == 1:
                            char_level = 1
                        else:
                            normalized_density = density / max_density
                            char_level = min(int(normalized_density * 9) + 1, 10)
                    style_for_best = get_style_for_level(char_level)
                    line_text.append("@", style=style_for_best)
                else:
                    density = density_grid[y, x]
                    if density == 0:
                        char_level = 0
                    else:
                        # Map density to color level (1-10 for non-zero densities)
                        if max_density == 1:
                            char_level = 1
                        else:
                            normalized_density = density / max_density
                            char_level = min(int(normalized_density * 9) + 1, 10)
                    
                    colored_char = get_colored_char(char_level)
                    line_text.append(colored_char)
            
            grid_lines.append(line_text)
        
        # Convert Rich Text objects to strings for the panel
        lines = []
        # Add compact header
        header = "    " + "".join([f"{i:2d}" if i % 20 == 0 else "  " for i in range(0, grid_width, 2)])
        lines.append(header[:grid_width + 4])
        
        # Add grid lines (we'll handle coloring in the panel)
        for line_text in grid_lines:
            lines.append(str(line_text))
        
        # Add legend and statistics
        variance_explained = np.sum(self.pca.explained_variance_ratio_) * 100
        lines.append("")
        lines.append("Legend: Â·=empty â–ª=density (blueâ†’cyanâ†’greenâ†’yellowâ†’bright_yellowâ†’redâ†’bright_red) @=global best (colored by density)")
        lines.append(f"PC1 vs PC2 | Variance explained: {variance_explained:.1f}% | Particles: {len(positions)} | Max density: {int(max_density)}")
        
        # Create Rich panel with colored content
        if RICH_AVAILABLE and hasattr(self, 'console'):
            # Create a combined Rich Text object for the entire visualization
            full_viz = Text()
            
            # Add header
            full_viz.append(lines[0] + "\n")
            
            # Add colored grid lines
            for line_text in grid_lines:
                full_viz.append(line_text)
                full_viz.append("\n")
            
            # Add legend and stats
            full_viz.append("\n")
            full_viz.append(lines[-2] + "\n")
            full_viz.append(lines[-1])
            
            panel = Panel(
                full_viz,
                title=f"ğŸ—ºï¸ Search Space Visualization - Iteration {iteration}",
                border_style="cyan",
                padding=(1, 2)
            )
            
            # Write to graphs file
            import contextlib
            with open(self.graphs_path, "a") as f, contextlib.redirect_stdout(f), contextlib.redirect_stderr(f):
                self.console.print(panel)
                # No extra spacing - panels will be adjacent

    def set_competition_config(self, enable=True, max_particles_per_cell=2, stagnation_window=15, eviction_percentage=40, check_interval=10):
        """Configure grid-based competitive evolution settings
        
        Parameters
        ----------
        enable : bool
            Enable/disable competitive evolution (default: True)
        max_particles_per_cell : int
            Maximum number of particles allowed per grid cell (default: 2)
        stagnation_window : int
            Number of iterations with unchanged cell-best to consider stagnant (default: 15)
        eviction_percentage : int
            Percentage of worst particles to evict from stagnant cells (default: 40)
        check_interval : int
            Check for competition every X iterations (default: 10)
        """
        self.competition_enabled = enable
        self.max_particles_per_cell = max_particles_per_cell
        self.stagnation_window = stagnation_window
        self.eviction_percentage = eviction_percentage
        self.competition_check_interval = check_interval
        
        # Update existing cell fitness history deques with new maxlen
        if hasattr(self, 'cell_fitness_history'):
            for grid_coords in self.cell_fitness_history:
                old_deque = self.cell_fitness_history[grid_coords]
                self.cell_fitness_history[grid_coords] = deque(old_deque, maxlen=stagnation_window)
        
        self.log_message(f"âš”ï¸ Competitive evolution: {'enabled' if enable else 'disabled'}", emoji="âš”ï¸")
        if enable:
            self.log_message(f"   ğŸ“Š Max {max_particles_per_cell} particles/cell, {eviction_percentage}% eviction, {stagnation_window}-iter stagnation window", emoji="ğŸ“Š")
            self.log_message(f"   ğŸ”„ Competition check every {check_interval} iterations", emoji="ğŸ”„")

    def set_blacklist_config(self, fitness_threshold=1e5, blacklist_window=100):
        """Configure cell blacklisting system settings
        
        Parameters
        ----------
        fitness_threshold : float
            Fitness threshold for blacklisting - cells with no fitness < threshold get blacklisted (default: 1e5)
        blacklist_window : int
            Number of iterations to track for blacklisting decisions (default: 100)
        """
        self.blacklist_fitness_threshold = fitness_threshold
        self.blacklist_window = blacklist_window
        
        # Update existing tracking deques with new maxlen
        if hasattr(self, 'cell_fitness_tracking'):
            for grid_coords in self.cell_fitness_tracking:
                old_deque = self.cell_fitness_tracking[grid_coords]
                self.cell_fitness_tracking[grid_coords] = deque(old_deque, maxlen=blacklist_window)
        
        if hasattr(self, 'cell_stagnation_tracking'):
            for grid_coords in self.cell_stagnation_tracking:
                old_deque = self.cell_stagnation_tracking[grid_coords]
                self.cell_stagnation_tracking[grid_coords] = deque(old_deque, maxlen=blacklist_window)
        
        self.log_message(f"ğŸš« Cell blacklisting: fitness threshold {fitness_threshold:.0e}, window {blacklist_window} iterations", emoji="ğŸš«")

    def set_velocity_boost_config(self, interval=10, fraction=0.20, enable=True, optimize_limits_len=5, use_exploration_prediction=True, n_alternative_swarms=200, prediction_steps=10, grid_refinement_threshold=95.0, max_grid_resolution=50):
        """Configure velocity boost settings with sophisticated particle selection
        
        Parameters
        ----------
        interval : int
            Apply velocity boost every X iterations (default: 10)
        fraction : float
            Maximum fraction of particles to boost (default: 0.20 = 20%, max 90%)
        enable : bool
            Enable/disable velocity boost (default: True)
        optimize_limits_len : int
            Length of optimize limits for fitness threshold calculation (default: 5)
        use_exploration_prediction : bool
            Enable multi-step exploration prediction for boost direction (default: True)
        n_alternative_swarms : int
            Number of alternative mini-swarms to test for exploration prediction (default: 200)
        prediction_steps : int
            Number of PSO iterations to simulate for each alternative (default: 10)
        grid_refinement_threshold : float
            Exploration saturation percentage at which to refine grid (default: 95.0%)
        max_grid_resolution : int
            Maximum allowed grid resolution to prevent memory issues (default: 50)
        """
        self.reinit_interval = interval
        self.reinit_fraction = fraction  # This is now the max fraction (up to 90%)
        self.enable_reinit = enable
        self.optimize_limits_len = optimize_limits_len
        self.use_exploration_prediction = use_exploration_prediction
        self.n_alternative_swarms = n_alternative_swarms
        self.prediction_steps = prediction_steps
        self.grid_refinement_threshold = grid_refinement_threshold
        self.max_grid_resolution = max_grid_resolution
        
        fitness_threshold = 10 ** optimize_limits_len
        self.log_message(f"ğŸš€ Smart velocity boost: {'enabled' if enable else 'disabled'} (every {interval} iters)", emoji="ğŸš€")
        self.log_message(f"   ğŸ“Š Selection: 20%-90% particles, fitness threshold: {fitness_threshold:.0e}", emoji="ğŸ“Š")
        if use_exploration_prediction:
            self.log_message(f"   ğŸ¯ Multi-step exploration prediction: enabled ({n_alternative_swarms} alternatives Ã— {prediction_steps} steps)", emoji="ğŸ¯")
            self.log_message(f"   ğŸ” Grid refinement: enabled at {grid_refinement_threshold}% saturation (max resolution: {max_grid_resolution})", emoji="ğŸ”")

    def set_initialization_strategy(self, strategy="hybrid"):
        """Set the initialization strategy for particle positions
        
        Parameters
        ----------
        strategy : str
            Initialization strategy. Options:
            - 'uniform': Standard uniform random (default PySwarms behavior)
            - 'lhs': Latin Hypercube Sampling (best space-filling)
            - 'sobol': Sobol sequences (low-discrepancy)
            - 'stratified': Stratified sampling (equal segments per dimension)
            - 'opposition': Opposition-Based Learning (explore opposites)
            - 'hybrid': Combination of multiple strategies (recommended)
        """
        valid_strategies = ['uniform', 'lhs', 'sobol', 'stratified', 'opposition', 'hybrid']
        if strategy not in valid_strategies:
            raise ValueError(f"Invalid strategy '{strategy}'. Must be one of {valid_strategies}")
        
        self.initialization_strategy = strategy
        self.log_message(f"ğŸ¯ Set initialization strategy to: {strategy}", emoji="ğŸ¯")

    def _calculate_search_space_exploration(self):
        """Calculate the percentage of search space explored using sparse grid coverage
        
        This method uses the sparse visited_cells set to track exploration without
        maintaining a dense grid array, making it checkpoint-friendly.
        
        Returns
        -------
        float
            Percentage of grid cells visited (0-100%)
        """
        if self.bounds is None:
            # For unbounded case, we can't calculate meaningful grid coverage
            # Return diversity as a proxy (normalized to 0-100%)
            positions = self.swarm.position
            diversity = np.mean(np.std(positions, axis=0))
            return min(diversity * 10, 100.0)  # Scale diversity to percentage
        
        # Initialize grid resolution if not exists (but don't create dense grid)
        if not hasattr(self, 'grid_resolution'):
            # Grid resolution per dimension (adjustable based on problem size)
            if self.dimensions <= 3:
                self.grid_resolution = 20  # 20^3 = 8,000 cells max
            elif self.dimensions <= 6:
                self.grid_resolution = 10  # 10^6 = 1,000,000 cells max
            elif self.dimensions <= 10:
                self.grid_resolution = 5   # 5^10 = 9,765,625 cells max
            else:
                self.grid_resolution = 3   # 3^n cells (manageable for high dimensions)
            
            self._total_grid_cells = self.grid_resolution ** self.dimensions
            self.log_message(f"ğŸ”¢ Sparse grid-based exploration tracking: {self.grid_resolution}^{self.dimensions} = {self._total_grid_cells:,} cells", emoji="ğŸ”¢")
        
        # Update visited cells with current positions
        self._update_visited_cells_sparse()
        
        # Calculate exploration percentage using sparse set
        visited_count = len(self.visited_cells)
        exploration_percentage = (visited_count / self._total_grid_cells) * 100.0
        
        return exploration_percentage

    def _update_visited_cells_sparse(self):
        """Update the sparse visited_cells set with current and historical positions"""
        
        if self.bounds is None:
            return
        
        # Get all historical positions (current + personal bests for comprehensive coverage)
        all_positions = np.vstack([
            self.swarm.position,           # Current positions
            self.swarm.pbest_pos          # Personal best positions
        ])
        
        # Convert positions to grid coordinates and add to sparse set
        for pos in all_positions:
            grid_coords = self._position_to_grid_coords(pos)
            if grid_coords is not None:
                self.visited_cells.add(grid_coords)

    def _boost_worst_particles_velocity(self, iteration):
        """Give particles a large velocity boost to explore new regions using sophisticated selection criteria
        
        Selection criteria:
        1) Worst fitness is prioritized
        2) Fitness which is above 10**len(optimize_limits) are to be boosted (up until 90% is reached)
        3) If (2) cannot reach 20%, we add the worst fitness from particles with fitness < 10**len(optimize_limits)
        
        Parameters
        ----------
        iteration : int
            Current iteration number
        """
        if not self.enable_reinit:
            return
            
        # Check if it's time for velocity boost (every n iterations)
        if iteration % self.reinit_interval != 0 or iteration == 0:
            return
        
        # Use adaptive boost strategy based on exploration saturation
        if getattr(self, 'use_exploration_prediction', True):
            self._adaptive_boost_strategy(iteration)
        else:
            self._boost_particles_traditional(iteration)

    def _boost_particles_traditional(self, iteration):
        """Traditional velocity boost method (original implementation)"""
        # Get fitness threshold - estimate optimize limits length as 5 (typical for trading optimization)
        # This could be made configurable if needed
        optimize_limits_len = getattr(self, 'optimize_limits_len', 5)
        fitness_threshold = 10 ** optimize_limits_len
        global_best_particle_idx = self._get_global_best_particle_idx()
        
        # Get all particle indices and their pbest fitness values (personal best performance)
        all_indices = np.arange(self.n_particles)
        all_pbest_fitness = self.swarm.pbest_cost
        
        # Remove global best particle from consideration
        eligible_indices = all_indices[all_indices != global_best_particle_idx]
        eligible_pbest_fitness = all_pbest_fitness[eligible_indices]
        
        # Separate eligible particles into high fitness (above threshold) and low fitness (below threshold)
        high_fitness_mask = eligible_pbest_fitness >= fitness_threshold
        low_fitness_mask = eligible_pbest_fitness < fitness_threshold
        
        high_fitness_indices = eligible_indices[high_fitness_mask]
        low_fitness_indices = eligible_indices[low_fitness_mask]
        
        # Calculate min and max boost counts (adjusted for protecting global best)
        max_eligible = len(eligible_indices)
        min_boost = max(1, int(0.20 * max_eligible))  # Minimum 20% of eligible particles
        max_boost = max(1, int(0.30 * max_eligible))  # Maximum 30% of eligible particles
        
        selected_indices = []
        
        # Step 1: Add all high pbest fitness particles (above threshold), prioritizing worst first
        if len(high_fitness_indices) > 0:
            # Sort high fitness particles by pbest fitness (worst first)
            high_fitness_sorted = high_fitness_indices[np.argsort(eligible_pbest_fitness[high_fitness_mask])[::-1]]
            # Take up to max_boost particles
            selected_indices.extend(high_fitness_sorted[:max_boost])
        
        # Step 2: If we haven't reached min_boost (20%), add worst particles from low fitness group
        if len(selected_indices) < min_boost and len(low_fitness_indices) > 0:
            # Sort low fitness particles by pbest fitness (worst first)
            low_fitness_sorted = low_fitness_indices[np.argsort(eligible_pbest_fitness[low_fitness_mask])[::-1]]
            # Add particles until we reach min_boost
            needed = min_boost - len(selected_indices)
            selected_indices.extend(low_fitness_sorted[:needed])
        
        # Convert to numpy array and ensure we don't exceed max_boost
        boost_indices = np.array(selected_indices[:max_boost])
        n_boost = len(boost_indices)
        
        if n_boost == 0:
            self.log_message("âš ï¸ No particles selected for velocity boost", emoji="âš ï¸")
            return
        
        # Use global best position to bias direction away from current best solution
        global_best_pos = self.swarm.best_pos
        
        # Ensure we have bounds for safe distance calculation
        if self.bounds is None:
            self.log_message("âš ï¸ No bounds specified, cannot perform safe velocity boost", emoji="âš ï¸")
            return
            
        lower_bounds, upper_bounds = self.bounds
        
        # Apply velocity boost to selected particles
        boosted_particles = []
        high_fitness_count = 0
        low_fitness_count = 0
        
        for idx in boost_indices:
            current_pos = self.swarm.position[idx]
            pbest_fitness = self.swarm.pbest_cost[idx]
            
            # Track selection categories
            if pbest_fitness >= fitness_threshold:
                high_fitness_count += 1
            else:
                low_fitness_count += 1
            
            # Calculate direction away from global best position
            away_vector = current_pos - global_best_pos
            away_norm = np.linalg.norm(away_vector)
            
            # Handle case where particle is at global best position
            if away_norm < 1e-10:
                away_vector = np.random.uniform(-1, 1, self.dimensions)
                away_norm = np.linalg.norm(away_vector)
            
            away_vector = away_vector / away_norm  # Normalize
            
            # Add randomness to direction (70% away from global best, 30% random)
            random_vector = np.random.uniform(-1, 1, self.dimensions)
            random_vector = random_vector / np.linalg.norm(random_vector)
            
            # Combine directions (70% away from global best,
            direction = 0.7 * away_vector + 0.3 * random_vector
            direction = direction / np.linalg.norm(direction)  # Normalize final direction
            
            # Calculate maximum safe distance in this direction (only for moving dimensions)
            max_distances = []
            for dim in range(self.dimensions):
                if abs(direction[dim]) >= 1e-10:  # Only calculate for moving dimensions
                    if direction[dim] > 0:  # Moving toward upper bound
                        max_dist = (upper_bounds[dim] - current_pos[dim]) / direction[dim]
                        max_distances.append(max_dist)
                    else:  # Moving toward lower bound
                        max_dist = (current_pos[dim] - lower_bounds[dim]) / abs(direction[dim])
                        max_distances.append(max_dist)
            
            safe_distance = np.mean(max_distances) if max_distances else 1.0
            
            # Set magnitude to average safe distance
            magnitude = safe_distance
            
            # Apply velocity boost
            self.swarm.velocity[idx] = magnitude * direction
            
            # Reset pbest for boosted particles - give them a fresh start
            self.swarm.pbest_cost[idx] = np.inf
            self.swarm.pbest_pos[idx] = current_pos.copy()  # Reset to current position
            
            boosted_particles.append({
                'idx': idx,
                'pbest_fitness': pbest_fitness,
                'magnitude': magnitude,
                'safe_distance': safe_distance
            })
        
        # Calculate pbest fitness statistics for the particles BEFORE boosting
        particles_to_boost_pbest_fitness = [p['pbest_fitness'] for p in boosted_particles]
        before_boost_stats = {
            'min': np.min(particles_to_boost_pbest_fitness),
            'max': np.max(particles_to_boost_pbest_fitness),
            'mean': np.mean(particles_to_boost_pbest_fitness)
        }
        
        # Store the boosted particle indices for tracking in next iteration
        self.last_boosted_indices = boost_indices.copy()
        self.last_boost_iteration = iteration
        
        # Log the sophisticated velocity boost with before/after statistics
        avg_magnitude = np.mean([p['magnitude'] for p in boosted_particles])
        boost_percentage = (n_boost / self.n_particles) * 100
        
        global_best_particle_idx = self._get_global_best_particle_idx()
        self.log_message(f"ğŸš€ Smart velocity boost applied to {n_boost}/{self.n_particles} particles ({boost_percentage:.1f}%) (global best particle #{global_best_particle_idx} protected)", emoji="ğŸš€")
        self.log_message(f"   ğŸ“Š Selection: High pbest (â‰¥{fitness_threshold:.0e}): {high_fitness_count}, Low pbest: {low_fitness_count}", emoji="ğŸ“Š")
        self.log_message(f"   ğŸ“ˆ Boosted particles pbest - Min: {before_boost_stats['min']:.6e}, Avg: {before_boost_stats['mean']:.6e}, Max: {before_boost_stats['max']:.6e}", emoji="ğŸ“ˆ")
        self.log_message(f"   ğŸ”„ Reset pbest for all boosted particles - fresh start opportunity", emoji="ğŸ”„")
        
        # Show "after boost" statistics if we have data from previous boost
        if hasattr(self, 'last_boosted_indices') and hasattr(self, 'last_boost_iteration') and self.last_boost_iteration == iteration - self.reinit_interval:
            # Get current fitness of previously boosted particles
            prev_boosted_current_fitness = self.swarm.current_cost[self.last_boosted_indices]
            after_boost_stats = {
                'min': np.min(prev_boosted_current_fitness),
                'max': np.max(prev_boosted_current_fitness),
                'mean': np.mean(prev_boosted_current_fitness)
            }
            self.log_message(f"   ğŸ“‰ Previous boosted particles fitness - Min: {after_boost_stats['min']:.6e}, Avg: {after_boost_stats['mean']:.6e}, Max: {after_boost_stats['max']:.6e}", emoji="ğŸ“‰")
        
        self.log_message(f"   âš¡ Avg velocity magnitude: {avg_magnitude:.6f}", emoji="âš¡")

    def _initialize_positions_with_strategy(self, n_particles, bounds):
        """Initialize particle positions using the selected strategy"""
        strategy = getattr(self, 'initialization_strategy', 'hybrid')
        
        if strategy == 'lhs':
            return self._generate_latin_hypercube_positions(n_particles, bounds)
        elif strategy == 'sobol':
            return self._generate_sobol_positions(n_particles, bounds)
        elif strategy == 'stratified':
            return self._generate_stratified_positions(n_particles, bounds)
        elif strategy == 'opposition':
            return self._generate_opposition_based_positions(n_particles, bounds)
        elif strategy == 'hybrid':
            return self._generate_hybrid_positions(n_particles, bounds)
        else:  # uniform
            return self._generate_uniform_positions(n_particles, bounds)

    def _inject_init_pos_fresh_start(self):
        """Inject init_pos particle during fresh start initialization"""
        if self.custom_init_pos is None:
            return
        
        # Validate init_pos dimensions
        init_pos = np.array(self.custom_init_pos)
        if init_pos.shape != (self.dimensions,):
            self.log_message(f"âš ï¸ init_pos shape {init_pos.shape} doesn't match dimensions {self.dimensions}, skipping injection", emoji="âš ï¸")
            return
        
        # Validate bounds if they exist
        if self.bounds is not None:
            lower_bounds, upper_bounds = self.bounds
            if not np.all((init_pos >= lower_bounds) & (init_pos <= upper_bounds)):
                self.log_message("âš ï¸ init_pos is outside bounds, clipping to bounds", emoji="âš ï¸")
                init_pos = np.clip(init_pos, lower_bounds, upper_bounds)
        
        # Replace the first particle with init_pos
        self.swarm.position[0] = init_pos.copy()
        
        # Give it a random velocity like other particles
        if self.velocity_clamp is not None:
            min_vel, max_vel = self.velocity_clamp
            self.swarm.velocity[0] = 0
            # self.swarm.velocity[0] = np.random.uniform(min_vel, max_vel, self.dimensions)
        else:
            if self.bounds is not None:
                lower_bounds, upper_bounds = self.bounds
                vel_range = 0.1 * (upper_bounds - lower_bounds)
                # self.swarm.velocity[0] = np.random.uniform(-vel_range, vel_range, self.dimensions)
                self.swarm.velocity[0] = 0
            else:
                self.swarm.velocity[0] = 0
                # self.swarm.velocity[0] = np.random.uniform(-0.1, 0.1, self.dimensions)
        
        self.log_message(f"ğŸ¯ Injected init_pos particle at position 0 (fresh start)", emoji="ğŸ¯")

    def _inject_init_pos_checkpoint_resume(self, objective_func, **kwargs):
        """Inject init_pos particle during checkpoint resume by replacing worst particle"""
        if self.custom_init_pos is None:
            return
        
        # Validate init_pos dimensions
        init_pos = np.array(self.custom_init_pos)
        if init_pos.shape != (self.dimensions,):
            self.log_message(f"âš ï¸ init_pos shape {init_pos.shape} doesn't match dimensions {self.dimensions}, skipping injection", emoji="âš ï¸")
            return
        
        # Validate bounds if they exist
        if self.bounds is not None:
            lower_bounds, upper_bounds = self.bounds
            if not np.all((init_pos >= lower_bounds) & (init_pos <= upper_bounds)):
                self.log_message("âš ï¸ init_pos is outside bounds, clipping to bounds", emoji="âš ï¸")
                init_pos = np.clip(init_pos, lower_bounds, upper_bounds)
        
        # Find the worst performing particle (highest pbest_cost)
        worst_particle_idx = np.argmax(self.swarm.pbest_cost)
        worst_fitness = self.swarm.pbest_cost[worst_particle_idx]
        
        # Replace worst particle with init_pos
        self.swarm.position[worst_particle_idx] = init_pos.copy()
        
        # Give it a random velocity
        if self.velocity_clamp is not None:
            min_vel, max_vel = self.velocity_clamp
            self.swarm.velocity[worst_particle_idx] = np.random.uniform(min_vel, max_vel, self.dimensions)
        else:
            if self.bounds is not None:
                lower_bounds, upper_bounds = self.bounds
                vel_range = 0.1 * (upper_bounds - lower_bounds)
                self.swarm.velocity[worst_particle_idx] = np.random.uniform(-vel_range, vel_range, self.dimensions)
            else:
                self.swarm.velocity[worst_particle_idx] = np.random.uniform(-0.1, 0.1, self.dimensions)
        
        # Evaluate the new particle to get its fitness
        # Create a temporary swarm with just this particle for evaluation
        temp_swarm = type('TempSwarm', (), {})()
        temp_swarm.position = init_pos.reshape(1, -1)
        temp_fitness = compute_objective_function(temp_swarm, objective_func, pool=None, **kwargs)
        
        # Update the particle's costs
        self.swarm.current_cost[worst_particle_idx] = temp_fitness[0]
        self.swarm.pbest_cost[worst_particle_idx] = temp_fitness[0]
        self.swarm.pbest_pos[worst_particle_idx] = init_pos.copy()
        
        # Recompute global best in case the new particle is better
        old_global_best = self.swarm.best_cost
        self.swarm.best_pos, self.swarm.best_cost = self.top.compute_gbest(self.swarm)
        
        # Log the injection
        if self.swarm.best_cost < old_global_best:
            improvement = old_global_best - self.swarm.best_cost
            self.log_message(f"ğŸŒŸ init_pos particle replaced worst (fitness: {worst_fitness:.6e}) and became NEW GLOBAL BEST! (fitness: {temp_fitness[0]:.6e}, improvement: {improvement:.6e})", emoji="ğŸŒŸ")
        else:
            self.log_message(f"ğŸ¯ init_pos particle replaced worst (fitness: {worst_fitness:.6e} â†’ {temp_fitness[0]:.6e}) at position {worst_particle_idx}", emoji="ğŸ¯")

    def optimize(
        self, objective_func, iters, n_processes=None, verbose=True, **kwargs
    ):
        """Optimize the swarm for a number of iterations with checkpoint support

        Performs the optimization to evaluate the objective
        function :code:`f` for a number of iterations :code:`iter.`

        Parameters
        ----------
        objective_func : callable
            objective function to be evaluated
        iters : int
            number of iterations
        n_processes : int
            number of processes to use for parallel particle evaluation (default: None = no parallelization)
        verbose : bool
            enable or disable the logs and progress bar (default: True = enable logs)
        kwargs : dict
            arguments for the objective function

        Returns
        -------
        tuple
            the global best cost and the global best position.
        """
        # Color constants
        CYAN = "\033[96m"
        RESET = "\033[0m"
        
        # Initialize timing
        self.start_time = time.time()
        
        # Try to load from checkpoint
        start_iter = self.load_checkpoint()
        if start_iter is None:
            start_iter = 0
            self.log_message("ğŸš€ Starting fresh PSO optimization", emoji="ğŸš€")
        
        # Apply verbosity
        if verbose:
            log_level = logging.INFO
        else:
            log_level = logging.NOTSET

        self.rep.log("Obj. func. args: {}".format(kwargs), lvl=logging.DEBUG)
        self.rep.log(
            "Optimize for {} iters with {}".format(iters, self.options),
            lvl=log_level,
        )
        
        self.log_message(f"ğŸ Starting PSO evolution from iteration {start_iter}", emoji="ğŸ")
        self.log_message(f"ğŸ“Š Swarm size: {self.n_particles}", emoji="ğŸ“Š")
        
        # Populate memory of the handlers
        self.bh.memory = self.swarm.position
        self.vh.memory = self.swarm.position

        # Setup Pool of processes for parallel evaluation
        # pool = None if n_processes is None else mp.Pool(n_processes)

        # Initialize if starting fresh
        if start_iter == 0:
            # Use advanced initialization strategy for better space coverage
            self.swarm.position = self._initialize_positions_with_strategy(self.n_particles, self.bounds)
            
            # Initialize velocities based on position bounds
            if self.velocity_clamp is not None:
                min_vel, max_vel = self.velocity_clamp
                self.swarm.velocity = np.random.uniform(min_vel, max_vel, (self.n_particles, self.dimensions))
            else:
                # Default velocity initialization based on position range
                if self.bounds is not None:
                    lower_bounds, upper_bounds = self.bounds
                    vel_range = 0.1 * (upper_bounds - lower_bounds)  # 10% of parameter range
                    self.swarm.velocity = np.random.uniform(-vel_range, vel_range, (self.n_particles, self.dimensions))
                else:
                    # Fallback velocity initialization
                    self.swarm.velocity = np.random.uniform(-0.1, 0.1, (self.n_particles, self.dimensions))
            
            # Handle init_pos injection for fresh start
            if self.custom_init_pos is not None:
                self._inject_init_pos_fresh_start()
            
            # Initialize pbest arrays before evaluation
            self.swarm.pbest_pos = self.swarm.position.copy()
            self.swarm.pbest_cost = np.full(self.n_particles, np.inf)
            
            # Evaluate all particles to get proper fitness values (not np.inf)
            self.swarm.current_cost = compute_objective_function(self.swarm, objective_func, pool=None, **kwargs)
            self.swarm.pbest_pos, self.swarm.pbest_cost = compute_pbest(self.swarm)
            self.swarm.best_pos, self.swarm.best_cost = self.top.compute_gbest(self.swarm)
            
            self.best_fitness_history = []
            self.stagnation_count = 0
            self.last_improvement_iter = 0
            
            self.log_message(f"ğŸ¯ Initial evaluation complete - Global best: {self.swarm.best_cost:.6e}", emoji="ğŸ¯")
        
        # Initialize sparse exploration grid if not already done (for both fresh start and checkpoint resume)
        if not hasattr(self, 'grid_resolution') and self.bounds is not None:
            self._initialize_exploration_grid()
            # Mark initial positions as visited in sparse grid
            self._update_exploration_grid(self.swarm.position)
        
        ftol_history = deque(maxlen=self.ftol_iter)
        previous_best_fitness = self.swarm.best_cost if hasattr(self.swarm, 'best_cost') else float('inf')
        
        # Main PSO iteration loop
        for i in range(start_iter, iters):
            iter_start_time = time.time()
            
            if RICH_AVAILABLE:
                self.console_wrapper(Rule(f"Iteration {i}", style="bold blue"))
            
            # Velocity boost for worst particles to escape stagnation
            self._boost_worst_particles_velocity(i)
            
            # Store previous personal best costs for improvement tracking and blacklist evaluation
            previous_pbest_cost = self.swarm.pbest_cost.copy()
            self._previous_pbest_costs = previous_pbest_cost  # Store for blacklist tracking
            
            # Compute cost for current position and personal best
            self.swarm.current_cost = compute_objective_function(self.swarm, objective_func, pool=None, **kwargs)
            self.swarm.pbest_pos, self.swarm.pbest_cost = compute_pbest(self.swarm)
            
            # Hill climber spawning detection - check for negative fitness
            if self.hill_climber_config['enable_hill_climbers']:
                self._detect_and_spawn_hill_climbers(i, objective_func, **kwargs)
                
                # Process existing hill climber groups
                self._process_hill_climber_groups(i, objective_func, **kwargs)
            
            # Calculate how many particles improved their personal best
            pbest_improvements = self.swarm.pbest_cost < previous_pbest_cost
            n_pbest_improvements = np.sum(pbest_improvements)
            
            # Set best_cost_yet_found for ftol
            best_cost_yet_found = self.swarm.best_cost if hasattr(self.swarm, 'best_cost') else float('inf')
            self.swarm.best_pos, self.swarm.best_cost = self.top.compute_gbest(self.swarm)
            
            # Track improvements and stagnation
            if self.swarm.best_cost < previous_best_fitness:
                improvement = previous_best_fitness - self.swarm.best_cost
                self.stagnation_count = 0
                self.last_improvement_iter = i
                previous_best_fitness = self.swarm.best_cost
                if verbose and RICH_AVAILABLE:
                    self.log_message(f"ğŸ‰ NEW GLOBAL BEST! ğŸ‰ Fitness: {self.swarm.best_cost:.6e} (improved by {improvement:.6e})", emoji="ğŸŒŸ")
                
                # Log the best particle's optimization status
                self._log_best_particle_status(i, objective_func, **kwargs)
            else:
                self.stagnation_count += 1
            
            self.best_fitness_history.append(self.swarm.best_cost)
            
            # Update sparse exploration grid with current positions
            if hasattr(self, 'grid_resolution'):
                self._update_exploration_grid(self.swarm.position)
            
            # Save to history
            hist = self.ToHistory(
                best_cost=self.swarm.best_cost,
                mean_pbest_cost=np.mean(self.swarm.pbest_cost),
                mean_neighbor_cost=self.swarm.best_cost,
                position=self.swarm.position,
                velocity=self.swarm.velocity,
            )
            self._populate_history(hist)
            
            # # Verify stop criteria based on the relative acceptable cost ftol
            # relative_measure = self.ftol * (1 + np.abs(best_cost_yet_found))
            # delta = (
            #     np.abs(self.swarm.best_cost - best_cost_yet_found)
            #     < relative_measure
            # )
            # if i < self.ftol_iter:
            #     ftol_history.append(delta)
            # else:
            #     ftol_history.append(delta)
            #     if all(ftol_history):
            #         if verbose:
            #             self.log_message(f"ğŸ¯ Convergence achieved at iteration {i}", emoji="ğŸ¯")
            #         break
            
            # Perform options update with adaptive inertia weight
            if self.adaptive_inertia:
                # Linear decrease from initial_w to final_w
                current_w = self.initial_w - (self.initial_w - self.final_w) * (i / iters)
                self.swarm.options['w'] = current_w
            
            self.swarm.options = self.oh(
                self.options, iternow=i, itermax=iters
            )
            
            # Perform velocity and position updates
            self.swarm.velocity = self.top.compute_velocity(
                self.swarm, self.velocity_clamp, self.vh, self.bounds
            )
            self.swarm.position = self.top.compute_position(
                self.swarm, self.bounds, self.bh
            )
            
            # Velocity restart mechanism
            velocities = self.swarm.velocity
            avg_velocity = np.mean(np.linalg.norm(velocities, axis=1))
            
            if avg_velocity < self.velocity_threshold:
                self.low_velocity_count += 1
                if self.low_velocity_count >= self.low_velocity_threshold:
                    # Restart velocities for a fraction of particles
                    n_restart = int(self.restart_fraction * self.n_particles)
                    restart_indices = np.random.choice(self.n_particles, n_restart, replace=False)
                    
                    # Calculate velocity bounds based on parameter bounds
                    if self.bounds is not None:
                        lower_bounds, upper_bounds = self.bounds
                        v_max = 0.1 * (upper_bounds - lower_bounds)  # 10% of parameter range
                        v_min = -v_max
                    else:
                        # Fallback if no bounds specified
                        v_max = np.ones(self.dimensions) * 0.1
                        v_min = -v_max
                    
                    # Restart velocities for selected particles
                    for idx in restart_indices:
                        self.swarm.velocity[idx] = np.random.uniform(v_min, v_max)
                    
                    self.low_velocity_count = 0  # Reset counter
                    
                    if verbose and RICH_AVAILABLE:
                        self.log_message(f"ğŸ”„ Velocity restart triggered! Restarted {n_restart} particles (avg_vel: {avg_velocity:.6e})", emoji="ğŸš€")
            else:
                self.low_velocity_count = 0  # Reset counter if velocity is healthy
            
            # Track iteration time
            iter_time = time.time() - iter_start_time
            self.generation_times.append(iter_time)
            
            # Show iteration statistics
            if verbose and RICH_AVAILABLE:
                avg_iter_time = sum(self.generation_times) / len(self.generation_times) if self.generation_times else 0
                
                # Calculate swarm statistics
                positions = self.swarm.position
                velocities = self.swarm.velocity
                diversity = np.mean(np.std(positions, axis=0))
                avg_velocity = np.mean(np.linalg.norm(velocities, axis=1))
                current_mean = np.mean(self.swarm.current_cost)
                current_std = np.std(self.swarm.current_cost)
                
                # Calculate convergence metric - average distance to global best
                distances_to_global_best = np.linalg.norm(positions - self.swarm.best_pos, axis=1)
                avg_convergence_distance = np.mean(distances_to_global_best)
                
                # Calculate search space exploration
                exploration_percentage = self._calculate_search_space_exploration()
                
                # Calculate generational best (best fitness in current iteration)
                generational_best = np.min(self.swarm.current_cost)
                generational_best_particle = np.argmin(self.swarm.current_cost)
                
                # Find which particle has the global best (based on personal best costs)
                global_best_particle = np.argmin(self.swarm.pbest_cost)
                
                # Stagnation status with emoji
                stagnation_emoji = "ğŸ”¥" if self.stagnation_count == 0 else "ğŸ˜´" if self.stagnation_count < 10 else "ğŸ’¤" if self.stagnation_count < 50 else "âš°ï¸"
                stagnation_info = f"ğŸ”„ Stagnation: {self.stagnation_count} iters {stagnation_emoji} (last improvement: iter {self.last_improvement_iter})"
                
                # Exploration status with emoji and additional info
                exploration_emoji = "ğŸ—ºï¸" if exploration_percentage > 80 else "ğŸ”" if exploration_percentage > 50 else "ğŸ¯" if exploration_percentage > 20 else "ğŸ“"
                
                # Calculate additional exploration metrics using sparse grid
                if hasattr(self, 'grid_resolution'):
                    visited_cells = len(self.visited_cells)
                    total_cells = self._total_grid_cells
                    exploration_detail = f"{visited_cells:,}/{total_cells:,} cells"
                else:
                    exploration_detail = "initializing..."
                
                # Get competition statistics
                competition_stats = self.get_competition_stats()
                if competition_stats["enabled"]:
                    competition_info = f"âš”ï¸ Competition: {len(self.visited_cells):,} visited cells"
                    if competition_stats["overcrowded_cells"] > 0:
                        competition_info += f", {competition_stats['overcrowded_cells']} overcrowded"
                    
                    # Add blacklist information
                    blacklist_count = competition_stats["blacklisted_cells"]
                    if blacklist_count > 0:
                        blacklist_percentage = competition_stats["blacklist_percentage"]
                        competition_info += f", {blacklist_count:,} blacklisted ({blacklist_percentage:.1f}%)"
                else:
                    competition_info = "âš”ï¸ Competition: disabled"
                
                self.log_message(
                    f"""{CYAN}ğŸŒŸ Iter {i}{RESET}
                    ğŸ Swarm size: {self.n_particles}
                    ğŸŒ Global best: {self.swarm.best_cost:.6e} (particle #{global_best_particle})
                    ğŸ† Generational best: {generational_best:.6e} (particle #{generational_best_particle})
                    ğŸ“Š  Mean fitness: {current_mean:.6e}
                    ğŸ“ˆ Std fitness: {current_std:.6e}
                    ğŸ¯ Personal best improvements: {n_pbest_improvements}/{self.n_particles} particles
                    {stagnation_info}
                    ğŸŒ€ Swarm diversity: {diversity:.6f}
                    ğŸ¯ Convergence radius: {avg_convergence_distance:.6f}
                    {exploration_emoji} Search space explored: {exploration_percentage:.6f}% ({exploration_detail})
                    {competition_info}
                    âš¡ Avg velocity: {avg_velocity:.6f}
                    ğŸ”§ Inertia (w): {self.swarm.options['w']:.3f}
                    â±ï¸ Iter time: {iter_time:.2f} sec / {(iter_time/60):.2f} min
                    ğŸ“† Avg iter time: {avg_iter_time:.2f} sec""",
                    panel=True, timestamp=False
                )
            
            # Update blacklist tracking and evaluate blacklist every iteration
            self._update_blacklist_tracking(i)
            self._evaluate_blacklist(i)
            
            # Run competitive evolution to prevent clustering
            self._run_competitive_evolution(i)
            
            # Create PCA visualization
            self._create_pca_visualization(i)
            
            # Save checkpoint every iteration
            if self.checkpoint_path:
                self.save_checkpoint(i)
            
            # Save detailed history data for analysis
            # self.save_history_data(i)
        
        # Obtain the final best_cost and the final best_position
        final_best_cost = self.swarm.best_cost.copy()
        final_best_pos = self.swarm.pbest_pos[
            self.swarm.pbest_cost.argmin()
        ].copy()
        
        # Final statistics
        total_time = time.time() - self.start_time
        if verbose:
            self.log_message(f"ğŸ•’ Total time: {total_time:.2f} seconds ({total_time/60:.2f} minutes)", emoji="ğŸ•’")
            self.log_message(f"ğŸ† Final best fitness: {final_best_cost:.6e}", emoji="ğŸ†")
        
        # Write report in log and return final cost and position
        self.rep.log(
            "Optimization finished | best cost: {}, best pos: {}".format(
                final_best_cost, final_best_pos
            ),
            lvl=log_level,
        )
        
        # Close Pool of Processes
        if n_processes is not None:
            pool.close()
            
        return (final_best_cost, final_best_pos)

    def _log_best_particle_status(self, iteration, objective_func, **kwargs):
        """Log the best particle's optimization status to file"""
        try:
            
            play_sound("sounds/fire.wav")
            # Ensure logs directory exists
            os.makedirs("logs", exist_ok=True)
            
            # Find the best particle
            best_particle_idx = np.argmin(self.swarm.pbest_cost)
            best_particle = self.swarm.pbest_pos[best_particle_idx]
            
            # The objective function in PSO context expects a swarm, but we need to evaluate a single particle
            # We need to access the global evaluator that was set up in the PSO function
            try:
                # Import the global variables from alternatives.py
                try:
                    import src.alternatives as alt
                except ImportError:
                    # Try alternative import path
                    import alternatives as alt
                    
                if hasattr(alt, 'pso_evaluator') and hasattr(alt, 'pso_optimizable_param_names'):
                    evaluator = alt.pso_evaluator
                    optimizable_param_names = alt.pso_optimizable_param_names
                    all_param_names = alt.pso_all_param_names
                    fixed_params = alt.pso_fixed_params
                    integer_params = alt.pso_integer_params
                    toolbox = alt.pso_toolbox
                    
                    # Create full individual from the best particle position
                    individual = alt.create_full_individual(
                        best_particle, optimizable_param_names, all_param_names, 
                        fixed_params, integer_params, toolbox
                    )
                    
                    # Log header information
                    with open(self.best_log_path, "a") as f, contextlib.redirect_stdout(f), contextlib.redirect_stderr(f):
                        timestamp = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                        print(f"\nğŸŒŸ NEW BEST PARTICLE STATUS - Iteration {iteration} - {timestamp}")
                        print(f"ğŸ¯ Best Fitness: {self.swarm.best_cost:.6e}")
                        print(f"ğŸ“Š Particle Index: {best_particle_idx}")
                        print("")
                        
                        # Evaluate with verbose output (this will show the optimization status table)
                        evaluator.evaluate(individual)
                    
                    self.log_message(f"ğŸŒŸ Best particle status logged to {self.best_log_path} (iteration {iteration})", emoji="ğŸŒŸ")
                else:
                    self.log_message("âš ï¸ PSO global variables not found, cannot log best particle status", emoji="âš ï¸")
                    
            except ImportError as e:
                self.log_message(f"âš ï¸ Could not import alternatives module: {e}", emoji="âš ï¸")
            except Exception as e:
                self.log_message(f"âš ï¸ Error accessing PSO globals: {e}", emoji="âš ï¸")
                
        except Exception as e:
            self.log_message(f"âš ï¸ Failed to log best particle status: {e}", emoji="âš ï¸")

    def _adaptive_boost_strategy(self, iteration):
        """Adaptive boost strategy based on exploration saturation"""
        
        # Calculate exploration saturation
        exploration_saturation = self._calculate_exploration_saturation()
        
        # Get refinement threshold (default to 95% if not set)
        refinement_threshold = getattr(self, 'grid_refinement_threshold', 95.0)
        
        # Determine strategy based on saturation level
        if exploration_saturation >= refinement_threshold:
            # High saturation - refine grid and continue exploration
            self.log_message(f"ğŸ¯ Exploration saturation: {exploration_saturation:.1f}% (â‰¥{refinement_threshold}%), refining grid resolution", emoji="ğŸ¯")
            self._refine_exploration_grid()
            self._boost_particles_with_exploration_prediction(iteration)
        else:
            # Normal saturation - use exploration prediction
            self.log_message(f"ğŸ¯ Exploration saturation: {exploration_saturation:.1f}%, using exploration prediction", emoji="ğŸ¯")
            self._boost_particles_with_exploration_prediction(iteration)

    def _calculate_exploration_saturation(self):
        """Calculate the percentage of search space explored using sparse grid"""
        
        if not hasattr(self, 'grid_resolution'):
            return 0.0
        
        visited_count = len(self.visited_cells)
        total_cells = self._total_grid_cells
        saturation = (visited_count / total_cells) * 100.0
        
        return saturation

    def _refine_exploration_grid(self):
        """Double the grid resolution to create new unexplored regions for finer exploration using sparse storage"""
        
        if not hasattr(self, 'grid_resolution'):
            self.log_message("âš ï¸ No exploration grid to refine", emoji="âš ï¸")
            return
        
        old_resolution = self.grid_resolution
        new_resolution = old_resolution * 2
        
        # Prevent excessive memory usage - limit maximum resolution
        max_resolution = getattr(self, 'max_grid_resolution', 50)
        if new_resolution > max_resolution:
            self.log_message(f"âš ï¸ Grid resolution limit reached ({max_resolution}), cannot refine further", emoji="âš ï¸")
            return
        
        try:
            self.log_message(f"ğŸ” Refining sparse exploration grid: {old_resolution}^{self.dimensions} â†’ {new_resolution}^{self.dimensions}", emoji="ğŸ”")
            
            # Create new visited cells set for higher resolution
            new_visited_cells = set()
            
            # Map old sparse coordinates to new higher-resolution coordinates
            for old_coords in self.visited_cells:
                # Each old cell becomes 2^dimensions new cells
                new_coords_base = tuple(coord * 2 for coord in old_coords)
                
                # Mark the corresponding 2^d cells in new grid as visited
                for offset in np.ndindex(tuple([2] * self.dimensions)):
                    new_coords = tuple(base + off for base, off in zip(new_coords_base, offset))
                    if all(coord < new_resolution for coord in new_coords):
                        new_visited_cells.add(new_coords)
            
            # Update grid attributes
            self.visited_cells = new_visited_cells
            self.grid_resolution = new_resolution
            self._total_grid_cells = new_resolution ** self.dimensions
            
            # Calculate new exploration statistics
            visited_count = len(self.visited_cells)
            new_saturation = (visited_count / self._total_grid_cells) * 100.0
            unexplored_cells = self._total_grid_cells - visited_count
            
            self.log_message(f"   ğŸ“Š New sparse grid: {self._total_grid_cells:,} total cells, {visited_count:,} visited ({new_saturation:.1f}%)", emoji="ğŸ“Š")
            self.log_message(f"   ğŸ—ºï¸ Created {unexplored_cells:,} new unexplored cells for finer exploration", emoji="ğŸ—ºï¸")
            
        except Exception as e:
            self.log_message(f"âš ï¸ Error refining sparse exploration grid: {e}", emoji="âš ï¸")

    def _boost_particles_with_exploration_prediction(self, iteration):
        """Boost particles using distance-maximization placement"""
        
        # Step 1: Select particles to boost using existing logic
        boost_indices = self._select_particles_for_boost()
        
        if len(boost_indices) == 0:
            self.log_message("âš ï¸ No particles selected for distance-maximization boost", emoji="âš ï¸")
            return
        
        # Calculate statistics for particles to be boosted (before boosting)
        particles_to_boost_pbest_fitness = self.swarm.pbest_cost[boost_indices]
        before_boost_stats = {
            'min': np.min(particles_to_boost_pbest_fitness),
            'max': np.max(particles_to_boost_pbest_fitness),
            'mean': np.mean(particles_to_boost_pbest_fitness)
        }
        
        # Count selection categories
        optimize_limits_len = getattr(self, 'optimize_limits_len', 5)
        fitness_threshold = 10 ** optimize_limits_len
        high_fitness_count = np.sum(particles_to_boost_pbest_fitness >= fitness_threshold)
        low_fitness_count = len(boost_indices) - high_fitness_count
        
        # Step 2: Find optimal positions using candidate-based farthest-point sampling
        optimal_positions = self._find_farthest_point_positions(len(boost_indices))
        
        # Step 3: Apply the optimal positions to the selected particles
        if optimal_positions is not None and len(optimal_positions) > 0:
            for i, particle_idx in enumerate(boost_indices):
                self.swarm.position[particle_idx] = optimal_positions[i]
                
                # Initialize random velocity
                self.swarm.velocity[particle_idx] = self._initialize_random_velocity()
                
                # Reset pbest to give fresh start
                self.swarm.pbest_pos[particle_idx] = optimal_positions[i]
                self.swarm.pbest_cost[particle_idx] = np.inf
            
            # Store the boosted particle indices for tracking in next iteration
            self.last_boosted_indices = boost_indices.copy()
            self.last_boost_iteration = iteration
            
            # Calculate boost statistics
            n_boost = len(boost_indices)
            boost_percentage = (n_boost / self.n_particles) * 100
            
            # Log detailed boost information
            global_best_particle_idx = self._get_global_best_particle_idx()
            self.log_message(f"   ğŸš€ Farthest-point boost applied to {n_boost}/{self.n_particles} particles ({boost_percentage:.1f}%) (global best particle #{global_best_particle_idx} protected)", emoji="ğŸš€")
            self.log_message(f"   ğŸ“Š Selection: High pbest (â‰¥{fitness_threshold:.0e}): {high_fitness_count}, Low pbest: {low_fitness_count}", emoji="ğŸ“Š")
            self.log_message(f"   ğŸ“ˆ Boosted particles pbest - Min: {before_boost_stats['min']:.6e}, Avg: {before_boost_stats['mean']:.6e}, Max: {before_boost_stats['max']:.6e}", emoji="ğŸ“ˆ")
            self.log_message(f"   ğŸ”„ Reset pbest for all boosted particles - fresh start opportunity", emoji="ğŸ”„")
            self.log_message(f"   ğŸ¯ Placed particles at farthest candidates from discovered regions", emoji="ğŸ¯")
            
            # Show "after boost" statistics if we have data from previous boost
            if hasattr(self, 'last_boosted_indices') and hasattr(self, 'last_boost_iteration') and self.last_boost_iteration == iteration - self.reinit_interval:
                # Get current fitness of previously boosted particles
                prev_boosted_current_fitness = self.swarm.current_cost[self.last_boosted_indices]
                after_boost_stats = {
                    'min': np.min(prev_boosted_current_fitness),
                    'max': np.max(prev_boosted_current_fitness),
                    'mean': np.mean(prev_boosted_current_fitness)
                }
                self.log_message(f"   ï¿½ Preveious boosted particles fitness - Min: {after_boost_stats['min']:.6e}, Avg: {after_boost_stats['mean']:.6e}, Max: {after_boost_stats['max']:.6e}", emoji="ğŸ“‰")
            
        else:
            # Fallback to traditional boost
            self.log_message("âš ï¸ Distance maximization failed, using traditional boost", emoji="âš ï¸")
            self._boost_particles_traditional(iteration)

    def _select_particles_for_boost(self):
        """Select particles for boosting using existing sophisticated criteria, protecting global best"""
        
        # Get fitness threshold
        optimize_limits_len = getattr(self, 'optimize_limits_len', 5)
        fitness_threshold = 10 ** optimize_limits_len
        global_best_particle_idx = self._get_global_best_particle_idx()
        
        # Get all particle indices and their pbest fitness values
        all_indices = np.arange(self.n_particles)
        all_pbest_fitness = self.swarm.pbest_cost
        
        # Remove global best particle from consideration
        eligible_indices = all_indices[all_indices != global_best_particle_idx]
        eligible_pbest_fitness = all_pbest_fitness[eligible_indices]
        
        # Separate eligible particles into high fitness (above threshold) and low fitness (below threshold)
        high_fitness_mask = eligible_pbest_fitness >= fitness_threshold
        low_fitness_mask = eligible_pbest_fitness < fitness_threshold
        
        high_fitness_indices = eligible_indices[high_fitness_mask]
        low_fitness_indices = eligible_indices[low_fitness_mask]
        
        # Calculate min and max boost counts (adjusted for protecting global best)
        max_eligible = len(eligible_indices)
        min_boost = max(1, int(0.20 * max_eligible))  # Minimum 20% of eligible particles
        max_boost = max(1, int(0.30 * max_eligible))  # Maximum 30% of eligible particles
        
        selected_indices = []
        
        # Step 1: Add all high pbest fitness particles (above threshold), prioritizing worst first
        if len(high_fitness_indices) > 0:
            # Sort high fitness particles by pbest fitness (worst first)
            high_fitness_sorted = high_fitness_indices[np.argsort(eligible_pbest_fitness[high_fitness_mask])[::-1]]
            # Take up to max_boost particles
            selected_indices.extend(high_fitness_sorted[:max_boost])
        
        # Step 2: If we haven't reached min_boost (20%), add worst particles from low fitness group
        if len(selected_indices) < min_boost and len(low_fitness_indices) > 0:
            # Sort low fitness particles by pbest fitness (worst first)
            low_fitness_sorted = low_fitness_indices[np.argsort(eligible_pbest_fitness[low_fitness_mask])[::-1]]
            # Add particles until we reach min_boost
            needed = min_boost - len(selected_indices)
            selected_indices.extend(low_fitness_sorted[:needed])
        
        # Convert to numpy array and ensure we don't exceed max_boost
        boost_indices = np.array(selected_indices[:max_boost])
        
        return boost_indices



    def _position_to_grid_coords(self, position):
        """Convert position to grid coordinates"""
        
        if not hasattr(self, 'grid_resolution') or self.bounds is None:
            return None
        
        lower_bounds, upper_bounds = self.bounds
        grid_coords = []
        
        for dim in range(self.dimensions):
            # Normalize position to [0, 1] range
            normalized_pos = (position[dim] - lower_bounds[dim]) / (upper_bounds[dim] - lower_bounds[dim])
            
            # Convert to grid index (clamp to valid range)
            grid_idx = int(normalized_pos * self.grid_resolution)
            grid_idx = max(0, min(grid_idx, self.grid_resolution - 1))
            grid_coords.append(grid_idx)
        
        return tuple(grid_coords)

    def _initialize_exploration_grid(self):
        """Initialize the sparse exploration grid for tracking visited regions"""
        
        if self.bounds is None:
            self.log_message("âš ï¸ Cannot initialize exploration grid without bounds", emoji="âš ï¸")
            return
        
        # Set grid resolution based on problem dimensions (if not already set)
        if not hasattr(self, 'grid_resolution'):
            if self.dimensions <= 3:
                self.grid_resolution = 20  # 20^3 = 8,000 cells max
            elif self.dimensions <= 6:
                self.grid_resolution = 10  # 10^6 = 1,000,000 cells max
            elif self.dimensions <= 10:
                self.grid_resolution = 5   # 5^10 = 9,765,625 cells max
            else:
                self.grid_resolution = 3   # 3^n cells (manageable for high dimensions)
        
        # Calculate total cells (but don't create dense grid)
        self._total_grid_cells = self.grid_resolution ** self.dimensions
        
        # Initialize discovered coords buffer for farthest-point sampling
        self._discovered_coords = deque(maxlen=self.fp_discovered_cap)
        
        # visited_cells set is already initialized in __init__
        self.log_message(f"ğŸ—ºï¸ Initialized sparse exploration grid: {self.grid_resolution}^{self.dimensions} = {self._total_grid_cells:,} cells", emoji="ğŸ—ºï¸")

    def _update_exploration_grid(self, positions):
        """Update sparse exploration grid with visited positions"""
        
        new_cells = 0
        for pos in positions:
            grid_coords = self._position_to_grid_coords(pos)
            if grid_coords is not None:
                if grid_coords not in self.visited_cells:
                    self.visited_cells.add(grid_coords)
                    new_cells += 1
                    # Track newly discovered coord for farthest-point sampling
                    if self._discovered_coords is not None:
                        self._discovered_coords.append(grid_coords)
        
        return new_cells

    def _find_farthest_point_positions(self, n_particles):
        """Find positions via candidate-based farthest-point sampling.
        
        This avoids enumerating all unexplored grid cells. It uses a candidate pool
        sampled in continuous space and maximizes the minimum distance to discovered
        regions (derived from the exploration grid and swarm/pbest positions).
        """
        try:
            # Gather discovered anchor positions
            anchors = []
            # 1) From discovered grid coords tracked incrementally
            if isinstance(self._discovered_coords, deque) and len(self._discovered_coords) > 0:
                # Convert a sample (all currently stored, already capped) to positions
                anchors.extend([self._grid_coords_to_position(coords) for coords in list(self._discovered_coords)])
            
            # 2) Add current swarm and pbest positions to anchors (sample/cap later)
            anchors.extend(list(self.swarm.position))
            anchors.extend(list(self.swarm.pbest_pos))
            
            if len(anchors) == 0:
                # No anchors yet, use initialization strategy
                self.log_message("ğŸ¯ No discovered anchors, using LHS initialization", emoji="ğŸ¯")
                return self._generate_latin_hypercube_positions(n_particles, self.bounds)
            
            # Convert anchors to numpy and cap to discovered_cap
            anchors_np = np.asarray(anchors, dtype=self.fp_dtype)
            if anchors_np.shape[0] > self.fp_discovered_cap:
                idx = np.random.choice(anchors_np.shape[0], self.fp_discovered_cap, replace=False)
                anchors_np = anchors_np[idx]
            
            # Generate candidate pool
            C = int(max(n_particles, self.fp_candidate_pool_size))
            candidates = self._generate_candidate_positions(C).astype(self.fp_dtype, copy=False)
            
            # Compute initial nearest distances from candidates to anchors
            # Use chunking to limit memory if needed
            def chunked_min_distance(cands, anchors, chunk=2000):
                nearest = np.full(cands.shape[0], np.inf, dtype=self.fp_dtype)
                for start in range(0, anchors.shape[0], chunk):
                    end = min(start + chunk, anchors.shape[0])
                    diff = cands[:, None, :] - anchors[None, start:end, :]
                    dist2 = np.sum(diff * diff, axis=2)
                    local_min = np.min(dist2, axis=1)
                    nearest = np.minimum(nearest, local_min)
                return np.sqrt(nearest).astype(self.fp_dtype, copy=False)
            
            nearest_dist = chunked_min_distance(candidates, anchors_np)
            
            # Greedy farthest-point selection
            selected = []
            for _ in range(n_particles):
                best_idx = int(np.argmax(nearest_dist))
                best_pos = candidates[best_idx]
                selected.append(best_pos)
                
                # Update nearest distances using the newly selected point
                diff = candidates - best_pos
                dist = np.sqrt(np.sum(diff * diff, axis=1)).astype(self.fp_dtype, copy=False)
                nearest_dist = np.minimum(nearest_dist, dist)
                
                # Optional: mask out selected index to avoid reselection
                nearest_dist[best_idx] = -np.inf
            
            self.log_message(f"ğŸ“Œ Farthest-point selected {len(selected)} positions from {C} candidates and {anchors_np.shape[0]} anchors", emoji="ğŸ“Œ")
            return np.asarray(selected, dtype=np.float64)
        except Exception as e:
            self.log_message(f"âš ï¸ Farthest-point sampling failed: {e}", emoji="âš ï¸")
            return self._generate_latin_hypercube_positions(n_particles, self.bounds)

    def _generate_candidate_positions(self, n_candidates):
        """Generate candidate positions in continuous space within bounds/center, avoiding blacklisted cells."""
        try:
            # Generate more candidates than needed to account for blacklisted cell filtering
            n_raw_candidates = n_candidates * 3  # Generate 3x more to account for blacklisted rejections
            
            if SCIPY_AVAILABLE and self.fp_use_sobol:
                sampler = qmc.Sobol(d=self.dimensions, scramble=True, seed=np.random.randint(0, 2**31))
                n_sobol = 2 ** int(np.ceil(np.log2(n_raw_candidates)))
                sample = sampler.random(n=n_sobol)[:n_raw_candidates]
                if self.bounds is not None:
                    lower, upper = self.bounds
                    raw_candidates = qmc.scale(sample, lower, upper)
                else:
                    raw_candidates = qmc.scale(sample, -self.center, self.center)
            elif SCIPY_AVAILABLE:
                sampler = qmc.LatinHypercube(d=self.dimensions, seed=np.random.randint(0, 2**31))
                sample = sampler.random(n=n_raw_candidates)
                if self.bounds is not None:
                    lower, upper = self.bounds
                    raw_candidates = qmc.scale(sample, lower, upper)
                else:
                    raw_candidates = qmc.scale(sample, -self.center, self.center)
            else:
                # Uniform fallback
                if self.bounds is not None:
                    lower, upper = self.bounds
                    raw_candidates = np.random.uniform(lower, upper, size=(n_raw_candidates, self.dimensions))
                else:
                    raw_candidates = np.random.uniform(-self.center, self.center, size=(n_raw_candidates, self.dimensions))
            
            # Filter out blacklisted cells
            valid_candidates = []
            blacklisted_rejections = 0
            
            for pos in raw_candidates:
                grid_coords = self._position_to_grid_coords(pos)
                if grid_coords is not None and grid_coords in self.blacklisted_cells:
                    blacklisted_rejections += 1
                    continue  # Skip blacklisted cells
                valid_candidates.append(pos)
                if len(valid_candidates) >= n_candidates:
                    break
            
            # If we don't have enough valid candidates, generate more with uniform sampling
            while len(valid_candidates) < n_candidates:
                if self.bounds is not None:
                    lower, upper = self.bounds
                    extra_pos = np.random.uniform(lower, upper, size=(1, self.dimensions))[0]
                else:
                    extra_pos = np.random.uniform(-self.center, self.center, size=(1, self.dimensions))[0]
                
                grid_coords = self._position_to_grid_coords(extra_pos)
                if grid_coords is None or grid_coords not in self.blacklisted_cells:
                    valid_candidates.append(extra_pos)
            
            # Log blacklist impact
            if blacklisted_rejections > 0:
                self.log_message(f"ğŸš« Rejected {blacklisted_rejections} blacklisted candidates during farthest-point sampling", emoji="ğŸš«")
            
            return np.asarray(valid_candidates[:n_candidates])
            
        except Exception as e:
            self.log_message(f"âš ï¸ Candidate generation failed: {e}, using uniform fallback", emoji="âš ï¸")
            if self.bounds is not None:
                lower, upper = self.bounds
                return np.random.uniform(lower, upper, size=(n_candidates, self.dimensions))
            else:
                return np.random.uniform(-self.center, self.center, size=(n_candidates, self.dimensions))

    def _initialize_random_velocity(self):
        """Initialize random velocity for a boosted particle"""
        
        if self.velocity_clamp is not None:
            min_vel, max_vel = self.velocity_clamp
            return np.random.uniform(min_vel, max_vel, self.dimensions)
        else:
            if self.bounds is not None:
                lower_bounds, upper_bounds = self.bounds
                vel_range = 0.1 * (upper_bounds - lower_bounds)  # 10% of parameter range
                return np.random.uniform(-vel_range, vel_range, self.dimensions)
            else:
                return np.random.uniform(-0.1, 0.1, self.dimensions)

    def _grid_coords_to_position(self, grid_coords):
        # Convert integer grid coordinates to continuous position within bounds/center
        if self.bounds is None:
            position = np.zeros(self.dimensions, dtype=float)
            for dim in range(self.dimensions):
                normalized = grid_coords[dim] / (self.grid_resolution - 1)
                position[dim] = (normalized - 0.5) * 2.0 * self.center
            return position

        lower, upper = self.bounds
        position = np.zeros(self.dimensions, dtype=float)
        for dim in range(self.dimensions):
            normalized = grid_coords[dim] / (self.grid_resolution - 1)
            position[dim] = lower[dim] + normalized * (upper[dim] - lower[dim])
        return position

    def _run_competitive_evolution(self, iteration):
        """Run grid-based competitive evolution to prevent clustering and improve exploration"""
        
        if not self.competition_enabled:
            return
        
        # Only run competition check at specified intervals
        if iteration % self.competition_check_interval != 0 or iteration == 0:
            return
        
        if not hasattr(self, 'grid_resolution') or self.bounds is None:
            self.log_message("âš ï¸ Competition requires exploration grid and bounds, skipping", emoji="âš ï¸")
            return
        
        # Step 1: Update cell occupancy mapping
        self._update_cell_occupancy()
        
        # Step 2: Update cell fitness history for stagnation detection
        # (This happens automatically in _is_cell_stagnant method)
        
        # Step 3: Check for overcrowding and stagnation
        particles_to_relocate = []
        
        # Handle overcrowding
        overcrowded_particles = self._resolve_overcrowding()
        particles_to_relocate.extend(overcrowded_particles)
        
        # Handle stagnation (only if we have enough history)
        if len(self.global_improvement_history) >= self.stagnation_window:
            stagnant_particles = self._resolve_stagnation(iteration)
            particles_to_relocate.extend(stagnant_particles)
        
        # Step 4: Relocate particles to unvisited cells
        if particles_to_relocate:
            self._relocate_particles(particles_to_relocate, iteration)
        
        # Log competition results
        if particles_to_relocate:
            global_best_particle_idx = self._get_global_best_particle_idx()
            self.log_message(f"âš”ï¸ Competitive evolution: relocated {len(particles_to_relocate)} particles (global best particle #{global_best_particle_idx} protected)", emoji="âš”ï¸")

    def _update_cell_occupancy(self):
        """Update mapping of grid cells to particle indices"""
        
        self.cell_occupancy = {}
        
        for particle_idx in range(self.n_particles):
            position = self.swarm.position[particle_idx]
            grid_coords = self._position_to_grid_coords(position)
            
            if grid_coords is not None:
                if grid_coords not in self.cell_occupancy:
                    self.cell_occupancy[grid_coords] = []
                self.cell_occupancy[grid_coords].append(particle_idx)
                
                # Track visited cells
                self.visited_cells.add(grid_coords)

    def _update_global_improvement_history(self, iteration):
        """Track global swarm improvement rate over time"""
        
        current_global_best = self.swarm.best_cost
        
        # Calculate improvement from previous iteration
        if len(self.global_improvement_history) > 0:
            previous_best = self.global_improvement_history[-1]['best_cost']
            improvement = max(0, previous_best - current_global_best)  # Positive improvement
        else:
            improvement = 0
        
        self.global_improvement_history.append({
            'iteration': iteration,
            'best_cost': current_global_best,
            'improvement': improvement
        })
        
        # Keep only the stagnation window worth of history
        if len(self.global_improvement_history) > self.stagnation_window:
            self.global_improvement_history.pop(0)

    def _resolve_overcrowding(self):
        """Identify and mark particles for relocation from overcrowded cells"""
        
        particles_to_relocate = []
        overcrowded_cells = 0
        global_best_particle_idx = self._get_global_best_particle_idx()
        
        for grid_coords, particle_indices in self.cell_occupancy.items():
            if len(particle_indices) > self.max_particles_per_cell:
                overcrowded_cells += 1
                
                # Sort particles by personal best fitness (worst first)
                particle_fitness = [(idx, self.swarm.pbest_cost[idx]) for idx in particle_indices]
                particle_fitness.sort(key=lambda x: x[1], reverse=True)  # Worst first
                
                # Mark excess particles for relocation, but protect global best particle
                excess_count = len(particle_indices) - self.max_particles_per_cell
                relocated_count = 0
                
                for i in range(len(particle_fitness)):
                    if relocated_count >= excess_count:
                        break
                    
                    particle_idx = particle_fitness[i][0]
                    
                    # Skip global best particle - it stays in its cell
                    if particle_idx == global_best_particle_idx:
                        continue
                    
                    particles_to_relocate.append({
                        'particle_idx': particle_idx,
                        'reason': 'overcrowding',
                        'cell': grid_coords,
                        'fitness': particle_fitness[i][1]
                    })
                    relocated_count += 1
        
        if overcrowded_cells > 0:
            self.log_message(f"   ğŸ“Š Overcrowding: {overcrowded_cells} cells exceed {self.max_particles_per_cell} particles", emoji="ğŸ“Š")
        
        return particles_to_relocate

    def _resolve_stagnation(self, iteration):
        """Identify and mark particles for relocation from stagnant cells based on cell-best unchanged"""
        
        particles_to_relocate = []
        global_best_particle_idx = self._get_global_best_particle_idx()
        stagnant_cells = 0
        
        for grid_coords, particle_indices in self.cell_occupancy.items():
            # Check if cell is stagnant (cell best unchanged for stagnation_window iterations)
            if self._is_cell_stagnant(grid_coords, iteration):
                stagnant_cells += 1
                
                # Sort particles by personal best fitness (worst first)
                particle_fitness = [(idx, self.swarm.pbest_cost[idx]) for idx in particle_indices]
                particle_fitness.sort(key=lambda x: x[1], reverse=True)  # Worst first
                
                # Mark worst percentage for relocation, but protect global best particle
                evict_count = max(1, int(len(particle_indices) * self.eviction_percentage / 100))
                relocated_count = 0
                
                for i in range(len(particle_fitness)):
                    if relocated_count >= evict_count:
                        break
                    
                    particle_idx = particle_fitness[i][0]
                    
                    # Skip global best particle - it stays in its cell
                    if particle_idx == global_best_particle_idx:
                        continue
                    
                    # Get stagnation info for logging
                    stagnation_iterations = self._get_cell_stagnation_duration(grid_coords)
                    
                    particles_to_relocate.append({
                        'particle_idx': particle_idx,
                        'reason': 'stagnation',
                        'cell': grid_coords,
                        'fitness': particle_fitness[i][1],
                        'stagnation_iterations': stagnation_iterations
                    })
                    relocated_count += 1
        
        if stagnant_cells > 0:
            self.log_message(f"   ğŸŒ Stagnation: {stagnant_cells} cells with unchanged cell-best for {self.stagnation_window}+ iterations", emoji="ğŸŒ")
        
        return particles_to_relocate

    def _is_cell_stagnant(self, grid_coords, iteration):
        """Check if a cell is stagnant (cell-best unchanged for stagnation_window iterations)"""
        
        # Initialize cell fitness history if not exists
        if grid_coords not in self.cell_fitness_history:
            self.cell_fitness_history[grid_coords] = deque(maxlen=self.stagnation_window)
        
        # Get current best fitness in this cell
        if grid_coords in self.cell_occupancy:
            particle_indices = self.cell_occupancy[grid_coords]
            cell_best_fitness = min(self.swarm.pbest_cost[idx] for idx in particle_indices)
        else:
            cell_best_fitness = np.inf
        
        # Add to history
        self.cell_fitness_history[grid_coords].append(cell_best_fitness)
        
        # Check for stagnation: cell-best unchanged for full window
        fitness_history = list(self.cell_fitness_history[grid_coords])
        
        # Need full window to detect stagnation
        if len(fitness_history) < self.stagnation_window:
            return False
        
        # Check if the best fitness has been unchanged (within small tolerance for numerical precision)
        first_best = fitness_history[0]
        tolerance = abs(first_best) * 1e-12 + 1e-15  # Relative + absolute tolerance
        
        # Cell is stagnant if all values in the window are essentially the same
        for fitness in fitness_history[1:]:
            if abs(fitness - first_best) > tolerance:
                return False  # Found improvement, not stagnant
        
        return True  # No improvement found in the entire window

    def _get_cell_stagnation_duration(self, grid_coords):
        """Get how many iterations the cell has been stagnant"""
        
        if grid_coords not in self.cell_fitness_history:
            return 0
        
        fitness_history = list(self.cell_fitness_history[grid_coords])
        if len(fitness_history) < 2:
            return 0
        
        # Count consecutive iterations with no improvement from the end
        current_best = fitness_history[-1]
        tolerance = abs(current_best) * 1e-12 + 1e-15
        stagnant_count = 1  # Current iteration
        
        # Count backwards while fitness remains unchanged
        for i in range(len(fitness_history) - 2, -1, -1):
            if abs(fitness_history[i] - current_best) <= tolerance:
                stagnant_count += 1
            else:
                break
        
        return stagnant_count

    def _relocate_particles(self, particles_to_relocate, iteration):
        """Relocate particles to unvisited cells using LHS sampling"""
        
        if not particles_to_relocate:
            return
        
        # Get unvisited cells for relocation
        unvisited_positions = self._sample_unvisited_positions(len(particles_to_relocate))
        
        if len(unvisited_positions) == 0:
            self.log_message("âš ï¸ No unvisited positions available for relocation", emoji="âš ï¸")
            return
        
        # Relocate particles
        relocated_count = 0
        overcrowding_count = 0
        stagnation_count = 0
        
        for i, particle_info in enumerate(particles_to_relocate):
            if i >= len(unvisited_positions):
                break  # Not enough unvisited positions
            
            particle_idx = particle_info['particle_idx']
            old_fitness = particle_info['fitness']
            reason = particle_info['reason']
            
            # Set new position
            new_position = unvisited_positions[i]
            self.swarm.position[particle_idx] = new_position
            
            # Reset velocity
            self.swarm.velocity[particle_idx] = self._initialize_random_velocity()
            
            # Reset personal best to give fresh start
            self.swarm.pbest_pos[particle_idx] = new_position.copy()
            self.swarm.pbest_cost[particle_idx] = np.inf
            
            relocated_count += 1
            if reason == 'overcrowding':
                overcrowding_count += 1
            elif reason == 'stagnation':
                stagnation_count += 1
        
        # Log relocation details
        self.log_message(f"   ğŸš€ Relocated {relocated_count} particles: {overcrowding_count} overcrowding, {stagnation_count} stagnation", emoji="ğŸš€")
        self.log_message(f"   ğŸ¯ Particles placed in unvisited regions with fresh velocities and reset pbest", emoji="ğŸ¯")
        
        # Calculate and log average cell density on populated cells
        if hasattr(self, 'cell_occupancy') and self.cell_occupancy:
            populated_cells = [len(particles) for particles in self.cell_occupancy.values() if len(particles) > 0]
            if populated_cells:
                avg_density = np.mean(populated_cells)
                max_density = max(populated_cells)
                min_density = min(populated_cells)
                total_populated_cells = len(populated_cells)
                self.log_message(f"   ğŸ“Š Cell density: avg {avg_density:.2f}, min {min_density}, max {max_density} particles/cell ({total_populated_cells} populated cells)", emoji="ğŸ“Š")

    def _sample_unvisited_positions(self, n_positions):
        """Sample positions in unvisited and non-blacklisted grid cells using LHS"""
        
        if not hasattr(self, 'grid_resolution') or self.bounds is None:
            return []
        
        try:
            # Generate candidate positions using LHS
            n_candidates = max(n_positions * 20, 2000)  # Generate more candidates to account for blacklisted cells
            
            if SCIPY_AVAILABLE:
                sampler = qmc.LatinHypercube(d=self.dimensions, seed=np.random.randint(0, 2**31))
                sample = sampler.random(n=n_candidates)
                lower_bounds, upper_bounds = self.bounds
                candidate_positions = qmc.scale(sample, lower_bounds, upper_bounds)
            else:
                # Fallback to uniform sampling
                lower_bounds, upper_bounds = self.bounds
                candidate_positions = np.random.uniform(lower_bounds, upper_bounds, (n_candidates, self.dimensions))
            
            # Filter to only unvisited and non-blacklisted cells
            valid_positions = []
            blacklisted_rejections = 0
            
            for pos in candidate_positions:
                grid_coords = self._position_to_grid_coords(pos)
                if grid_coords is not None:
                    # Check if cell is unvisited
                    if grid_coords not in self.visited_cells:
                        # Check if cell is blacklisted
                        if grid_coords in self.blacklisted_cells:
                            blacklisted_rejections += 1
                            continue  # Skip blacklisted cells
                        valid_positions.append(pos)
                        if len(valid_positions) >= n_positions:
                            break
            
            # If not enough valid positions found with LHS, try uniform sampling of all valid cells
            if len(valid_positions) < n_positions:
                additional_needed = n_positions - len(valid_positions)
                additional_positions = self._uniform_sample_valid_cells(additional_needed)
                valid_positions.extend(additional_positions)
            
            # Log blacklist impact
            if blacklisted_rejections > 0:
                self.log_message(f"ğŸš« Rejected {blacklisted_rejections} blacklisted candidates during sampling", emoji="ğŸš«")
            
            return valid_positions[:n_positions]
            
        except Exception as e:
            self.log_message(f"âš ï¸ Error sampling unvisited positions: {e}", emoji="âš ï¸")
            return []

    def _uniform_sample_unvisited_cells(self, n_positions):
        """Uniform sampling fallback for unvisited cells (legacy method)"""
        return self._uniform_sample_valid_cells(n_positions)

    def _uniform_sample_valid_cells(self, n_positions):
        """Uniform sampling fallback for unvisited and non-blacklisted cells"""
        
        if not hasattr(self, 'grid_resolution') or self.bounds is None:
            return []
        
        try:
            # Generate all possible grid coordinates
            grid_ranges = [range(self.grid_resolution) for _ in range(self.dimensions)]
            all_coords = list(itertools.product(*grid_ranges))
            
            # Filter to unvisited and non-blacklisted coordinates
            valid_coords = []
            for coords in all_coords:
                if coords not in self.visited_cells and coords not in self.blacklisted_cells:
                    valid_coords.append(coords)
            
            if len(valid_coords) == 0:
                self.log_message("âš ï¸ No valid (unvisited + non-blacklisted) cells available", emoji="âš ï¸")
                return []
            
            # Sample random valid coordinates
            n_sample = min(n_positions, len(valid_coords))
            sampled_indices = np.random.choice(len(valid_coords), n_sample, replace=False)
            
            # Convert to positions
            positions = []
            for idx in sampled_indices:
                grid_coords = valid_coords[idx]
                position = self._grid_coords_to_position(grid_coords)
                positions.append(position)
            
            return positions
            
        except Exception as e:
            self.log_message(f"âš ï¸ Error in uniform sampling fallback: {e}", emoji="âš ï¸")
            return []

    def _get_global_best_particle_idx(self):
        """Get the index of the particle with the global best personal best fitness
        
        Returns
        -------
        int
            Index of the particle with the best personal best fitness
        """
        return np.argmin(self.swarm.pbest_cost)

    def _update_blacklist_tracking(self, iteration):
        """Update tracking data for blacklist evaluation"""
        
        if not hasattr(self, 'grid_resolution') or self.bounds is None:
            return
        
        # Update cell occupancy first
        self._update_cell_occupancy()
        
        # Track fitness and stagnation for each occupied cell
        for grid_coords, particle_indices in self.cell_occupancy.items():
            # Initialize tracking if not exists
            if grid_coords not in self.cell_fitness_tracking:
                self.cell_fitness_tracking[grid_coords] = deque(maxlen=self.blacklist_window)
            if grid_coords not in self.cell_stagnation_tracking:
                self.cell_stagnation_tracking[grid_coords] = deque(maxlen=self.blacklist_window)
            
            # Get current cell best fitness
            cell_best_fitness = min(self.swarm.pbest_cost[idx] for idx in particle_indices)
            
            # Track fitness
            self.cell_fitness_tracking[grid_coords].append((iteration, cell_best_fitness))
            
            # Track stagnation - check if any particle improved its personal best this iteration
            had_improvement = False
            for particle_idx in particle_indices:
                # Check if this particle's current cost is better than its previous pbest
                # (This would indicate an improvement happened this iteration)
                if hasattr(self, '_previous_pbest_costs'):
                    if self.swarm.current_cost[particle_idx] < self._previous_pbest_costs[particle_idx]:
                        had_improvement = True
                        break
            
            self.cell_stagnation_tracking[grid_coords].append((iteration, had_improvement))

    def _evaluate_blacklist(self, iteration):
        """Evaluate cells for blacklisting and removal from blacklist"""
        
        if not hasattr(self, 'grid_resolution') or self.bounds is None:
            return
        
        newly_blacklisted = set()
        removed_from_blacklist = set()
        
        # Check all cells with tracking data
        all_tracked_cells = set(self.cell_fitness_tracking.keys()) | set(self.cell_stagnation_tracking.keys())
        
        for grid_coords in all_tracked_cells:
            is_currently_blacklisted = grid_coords in self.blacklisted_cells
            
            # Get tracking data
            fitness_history = self.cell_fitness_tracking.get(grid_coords, deque())
            stagnation_history = self.cell_stagnation_tracking.get(grid_coords, deque())
            
            # Only evaluate if we have enough history
            if len(fitness_history) >= self.blacklist_window or len(stagnation_history) >= self.blacklist_window:
                
                should_be_blacklisted = False
                
                # Check fitness criterion: no fitness < threshold for blacklist_window iterations
                if len(fitness_history) >= self.blacklist_window:
                    recent_fitness = [fitness for _, fitness in list(fitness_history)[-self.blacklist_window:]]
                    if all(fitness >= self.blacklist_fitness_threshold for fitness in recent_fitness):
                        should_be_blacklisted = True
                
                # Check stagnation criterion: no improvements for blacklist_window iterations
                if len(stagnation_history) >= self.blacklist_window:
                    recent_improvements = [improved for _, improved in list(stagnation_history)[-self.blacklist_window:]]
                    if not any(recent_improvements):  # No improvements in the window
                        should_be_blacklisted = True
                
                # Update blacklist status
                if should_be_blacklisted and not is_currently_blacklisted:
                    self.blacklisted_cells.add(grid_coords)
                    newly_blacklisted.add(grid_coords)
                elif not should_be_blacklisted and is_currently_blacklisted:
                    self.blacklisted_cells.discard(grid_coords)
                    removed_from_blacklist.add(grid_coords)
        
        # Log blacklist changes
        if newly_blacklisted:
            self.log_message(f"ğŸš« Blacklisted {len(newly_blacklisted)} cells (poor fitness or stagnation)", emoji="ğŸš«")
        
        if removed_from_blacklist:
            self.log_message(f"âœ… Removed {len(removed_from_blacklist)} cells from blacklist (improvement detected)", emoji="âœ…")
        
        # Log current blacklist status
        if len(self.blacklisted_cells) > 0:
            total_cells = getattr(self, '_total_grid_cells', 1)
            blacklist_percentage = (len(self.blacklisted_cells) / total_cells) * 100
            self.log_message(f"ğŸš« Current blacklist: {len(self.blacklisted_cells):,} cells ({blacklist_percentage:.2f}% of search space)", emoji="ğŸš«")

    def get_competition_stats(self):
        """Get current competitive evolution and blacklist statistics
        
        Returns
        -------
        dict
            Dictionary containing competition and blacklist statistics
        """
        if not self.competition_enabled:
            return {"enabled": False}
        
        stats = {
            "enabled": True,
            "visited_cells": len(self.visited_cells),
            "total_possible_cells": getattr(self, '_total_grid_cells', 0),
            "exploration_percentage": 0.0,
            "current_cell_occupancy": {},
            "overcrowded_cells": 0,
            "stagnant_cells": 0,
            "global_improvement_rate": 0.0,
            "blacklisted_cells": len(getattr(self, 'blacklisted_cells', set())),
            "blacklist_percentage": 0.0
        }
        
        # Calculate exploration percentage
        if hasattr(self, '_total_grid_cells') and self._total_grid_cells > 0:
            stats["exploration_percentage"] = (len(self.visited_cells) / self._total_grid_cells) * 100.0
            stats["blacklist_percentage"] = (len(getattr(self, 'blacklisted_cells', set())) / self._total_grid_cells) * 100.0
        
        # Update cell occupancy and count overcrowded cells
        if hasattr(self, 'cell_occupancy'):
            stats["current_cell_occupancy"] = {str(k): len(v) for k, v in self.cell_occupancy.items()}
            stats["overcrowded_cells"] = sum(1 for v in self.cell_occupancy.values() if len(v) > self.max_particles_per_cell)
        
        # Calculate global improvement rate
        if len(self.global_improvement_history) > 0:
            improvements = [entry['improvement'] for entry in self.global_improvement_history]
            stats["global_improvement_rate"] = np.mean(improvements)
        
        return stats

    def _detect_and_spawn_hill_climbers(self, iteration, objective_func, **kwargs):
        """Detect negative fitness and spawn hill climber groups
        
        Parameters
        ----------
        iteration : int
            Current iteration number
        objective_func : callable
            Objective function for evaluation
        **kwargs : dict
            Additional arguments for objective function
        """
        if not self.hill_climber_config['enable_hill_climbers']:
            return
        
        # Check if we've reached the maximum number of concurrent groups
        if len(self.active_hill_climber_groups) >= self.hill_climber_config['max_concurrent_groups']:
            return
        
        negative_threshold = self.hill_climber_config['negative_fitness_threshold']
        
        # Check each PSO particle for negative fitness
        for particle_idx in range(self.n_particles):
            current_fitness = self.swarm.current_cost[particle_idx]
            
            # Check if fitness is negative (below threshold)
            if current_fitness < negative_threshold:
                # Spawn hill climber group at this location
                spawn_point = self.swarm.position[particle_idx].copy()
                group_id = self._spawn_hill_climber_group(
                    spawner_particle_id=particle_idx,
                    spawn_point=spawn_point,
                    trigger_fitness=current_fitness,
                    iteration=iteration
                )
                
                if group_id is not None:
                    # Record the spawning event
                    self._record_spawning_event(
                        iteration=iteration,
                        spawner_particle_id=particle_idx,
                        spawn_point=spawn_point,
                        trigger_fitness=current_fitness,
                        group_id=group_id
                    )
                    
                    # Log spawning event
                    self.log_message(
                        f"ğŸŒ± Hill climber group spawned! Particle #{particle_idx} "
                        f"(fitness: {current_fitness:.6e}) spawned group {group_id} "
                        f"with {self.hill_climber_config['climbers_per_spawn']} climbers",
                        emoji="ğŸŒ±"
                    )

    def _spawn_hill_climber_group(self, spawner_particle_id, spawn_point, trigger_fitness, iteration):
        """Create a new hill climber group at the specified spawn point
        
        Parameters
        ----------
        spawner_particle_id : int
            Index of the PSO particle that triggered spawning
        spawn_point : np.ndarray
            Position where the hill climber group should be spawned
        trigger_fitness : float
            Fitness value that triggered the spawning
        iteration : int
            Current iteration number
            
        Returns
        -------
        str or None
            Group ID if successful, None if spawning failed
        """
        try:
            # Generate unique group ID
            group_id = f"hc_group_{self._next_group_id}"
            self._next_group_id += 1
            
            # Create hill climber particles for this group
            climber_ids = []
            climbers_per_spawn = self.hill_climber_config['climbers_per_spawn']
            
            for i in range(climbers_per_spawn):
                climber_id = f"hc_{self._next_hill_climber_id}"
                self._next_hill_climber_id += 1
                
                # Initialize hill climber particle at spawn point
                hill_climber_particle = {
                    'id': climber_id,
                    'position': spawn_point.copy(),
                    'velocity': np.zeros(self.dimensions),  # Start with zero velocity
                    'group_id': group_id,
                    'assigned_point': None,  # Will be set during hill climbing phase
                    'local_best': spawn_point.copy(),
                    'local_best_fitness': np.inf
                }
                
                self.hill_climber_particles[climber_id] = hill_climber_particle
                climber_ids.append(climber_id)
            
            # Create hill climber group
            hill_climber_group = {
                'id': group_id,
                'spawner_id': spawner_particle_id,
                'spawn_point': spawn_point.copy(),
                'best_point': spawn_point.copy(),
                'best_fitness': trigger_fitness,
                'remaining_iterations': self.hill_climber_config['hill_climber_lifetime'],
                'climber_ids': climber_ids,
                'phase': 'radial_sampling',
                'ocean_hit_percentage': 0.0,
                'best_M_points': [],
                'current_radius': self._calculate_initial_radius(),
                'radius_increment': self._calculate_radius_increment(),
                'samples_taken': 0,
                'ocean_hits': 0
            }
            
            self.active_hill_climber_groups[group_id] = hill_climber_group
            
            return group_id
            
        except Exception as e:
            self.log_message(f"âš ï¸ Failed to spawn hill climber group: {e}", emoji="âš ï¸")
            return None

    def _record_spawning_event(self, iteration, spawner_particle_id, spawn_point, trigger_fitness, group_id):
        """Record a hill climber spawning event for tracking and analysis
        
        Parameters
        ----------
        iteration : int
            Current iteration number
        spawner_particle_id : int
            Index of the PSO particle that triggered spawning
        spawn_point : np.ndarray
            Position where the hill climber group was spawned
        trigger_fitness : float
            Fitness value that triggered the spawning
        group_id : str
            ID of the spawned hill climber group
        """
        spawning_event = {
            'iteration': iteration,
            'spawner_particle_id': spawner_particle_id,
            'spawn_point': spawn_point.copy(),
            'trigger_fitness': trigger_fitness,
            'group_id': group_id,
            'timestamp': time.time()
        }
        
        self.spawning_history.append(spawning_event)

    def _calculate_initial_radius(self):
        """Calculate initial radius for radial sampling as percentage of parameter ranges
        
        Returns
        -------
        float
            Initial radius for radial sampling
        """
        if self.bounds is None:
            # Use center-based calculation if no bounds
            return self.hill_climber_config['initial_radius_percentage'] * np.mean(self.center)
        
        lower_bounds, upper_bounds = self.bounds
        parameter_ranges = upper_bounds - lower_bounds
        avg_range = np.mean(parameter_ranges)
        
        return self.hill_climber_config['initial_radius_percentage'] * avg_range

    def _calculate_radius_increment(self):
        """Calculate radius increment for radial sampling as percentage of parameter ranges
        
        Returns
        -------
        float
            Radius increment for radial sampling
        """
        if self.bounds is None:
            # Use center-based calculation if no bounds
            return self.hill_climber_config['radius_increment_percentage'] * np.mean(self.center)
        
        lower_bounds, upper_bounds = self.bounds
        parameter_ranges = upper_bounds - lower_bounds
        avg_range = np.mean(parameter_ranges)
        
        return self.hill_climber_config['radius_increment_percentage'] * avg_range

    def _perform_radial_sampling(self, group_id, objective_func, **kwargs):
        """Perform radial sampling for a hill climber group with maximum angular coverage
        
        Parameters
        ----------
        group_id : str
            ID of the hill climber group to perform radial sampling for
        objective_func : callable
            Objective function for evaluation
        **kwargs : dict
            Additional arguments for objective function
            
        Returns
        -------
        bool
            True if sampling was performed successfully, False otherwise
        """
        if group_id not in self.active_hill_climber_groups:
            return False
        
        group = self.active_hill_climber_groups[group_id]
        
        # Only perform radial sampling if in the correct phase
        if group['phase'] != 'radial_sampling':
            return False
        
        try:
            spawn_point = group['spawn_point']
            current_radius = group['current_radius']
            climber_ids = group['climber_ids']
            
            # Generate positions with maximum angular coverage around spawn point
            sampling_positions = self._generate_angular_coverage_positions(
                spawn_point, current_radius, len(climber_ids)
            )
            
            # Update hill climber particle positions
            for i, climber_id in enumerate(climber_ids):
                if i < len(sampling_positions):
                    self.hill_climber_particles[climber_id]['position'] = sampling_positions[i]
            
            # Evaluate all hill climber positions
            hill_climber_positions = np.array([
                self.hill_climber_particles[climber_id]['position'] 
                for climber_id in climber_ids
            ])
            
            # Create temporary swarm for evaluation
            temp_swarm = type('TempSwarm', (), {})()
            temp_swarm.position = hill_climber_positions
            
            # Evaluate fitness
            fitness_values = compute_objective_function(temp_swarm, objective_func, pool=None, **kwargs)
            
            # Update hill climber particles with fitness results
            ocean_threshold = self.hill_climber_config['ocean_fitness_threshold']
            ocean_hits = 0
            best_fitness = np.inf
            best_position = None
            
            for i, climber_id in enumerate(climber_ids):
                fitness = fitness_values[i]
                position = sampling_positions[i]
                
                # Update hill climber particle
                self.hill_climber_particles[climber_id]['local_best_fitness'] = fitness
                self.hill_climber_particles[climber_id]['local_best'] = position.copy()
                
                # Count ocean hits
                if fitness > ocean_threshold:
                    ocean_hits += 1
                
                # Track best point found
                if fitness < best_fitness:
                    best_fitness = fitness
                    best_position = position.copy()
            
            # Update group statistics
            group['samples_taken'] += len(climber_ids)
            group['ocean_hits'] += ocean_hits
            
            # Update group best if we found something better
            if best_fitness < group['best_fitness']:
                group['best_fitness'] = best_fitness
                group['best_point'] = best_position
            
            # Calculate ocean hit percentage
            group['ocean_hit_percentage'] = self._calculate_ocean_hit_percentage(group_id)
            
            # Increment radius for next sampling iteration
            group['current_radius'] += group['radius_increment']
            
            # Log sampling progress
            self.log_message(
                f"ğŸ” Radial sampling - Group {group_id}: radius {current_radius:.4f}, "
                f"{ocean_hits}/{len(climber_ids)} ocean hits ({group['ocean_hit_percentage']:.1f}%), "
                f"best fitness: {best_fitness:.6e}",
                emoji="ğŸ”"
            )
            
            # Check if we should transition to hill climbing phase
            if group['ocean_hit_percentage'] >= self.hill_climber_config['ocean_hit_threshold'] * 100:
                self._transition_to_hill_climbing(group_id)
            
            return True
            
        except Exception as e:
            self.log_message(f"âš ï¸ Error in radial sampling for group {group_id}: {e}", emoji="âš ï¸")
            return False

    def _generate_angular_coverage_positions(self, center_point, radius, num_positions):
        """Generate positions with maximum angular coverage around a center point
        
        Parameters
        ----------
        center_point : np.ndarray
            Center point for radial sampling
        radius : float
            Radius for sampling
        num_positions : int
            Number of positions to generate
            
        Returns
        -------
        list of np.ndarray
            List of positions with maximum angular coverage
        """
        positions = []
        
        if self.dimensions == 1:
            # 1D case - sample on both sides
            for i in range(num_positions):
                direction = 1 if i % 2 == 0 else -1
                position = center_point + direction * radius
                
                # Ensure position is within bounds if bounds exist
                if self.bounds is not None:
                    lower_bounds, upper_bounds = self.bounds
                    position = np.clip(position, lower_bounds, upper_bounds)
                
                positions.append(position)
        
        elif self.dimensions == 2:
            # 2D case - distribute evenly around circle
            for i in range(num_positions):
                angle = 2 * np.pi * i / num_positions
                direction = np.array([np.cos(angle), np.sin(angle)])
                position = center_point + radius * direction
                
                # Ensure position is within bounds if bounds exist
                if self.bounds is not None:
                    lower_bounds, upper_bounds = self.bounds
                    position = np.clip(position, lower_bounds, upper_bounds)
                
                positions.append(position)
        
        else:
            # Higher dimensional case - use spherical explosion pattern
            # Generate random unit vectors and scale by radius
            for i in range(num_positions):
                # Generate random direction vector
                direction = np.random.randn(self.dimensions)
                direction = direction / np.linalg.norm(direction)  # Normalize to unit vector
                
                position = center_point + radius * direction
                
                # Ensure position is within bounds if bounds exist
                if self.bounds is not None:
                    lower_bounds, upper_bounds = self.bounds
                    position = np.clip(position, lower_bounds, upper_bounds)
                
                positions.append(position)
        
        return positions

    def _calculate_ocean_hit_percentage(self, group_id):
        """Calculate the percentage of samples that returned ocean fitness values
        
        Parameters
        ----------
        group_id : str
            ID of the hill climber group
            
        Returns
        -------
        float
            Percentage of samples that hit ocean fitness (0-100)
        """
        if group_id not in self.active_hill_climber_groups:
            return 0.0
        
        group = self.active_hill_climber_groups[group_id]
        
        if group['samples_taken'] == 0:
            return 0.0
        
        return (group['ocean_hits'] / group['samples_taken']) * 100.0

    def _transition_to_hill_climbing(self, group_id):
        """Transition a hill climber group from radial sampling to hill climbing phase
        
        Parameters
        ----------
        group_id : str
            ID of the hill climber group to transition
            
        Returns
        -------
        bool
            True if transition was successful, False otherwise
        """
        if group_id not in self.active_hill_climber_groups:
            return False
        
        group = self.active_hill_climber_groups[group_id]
        
        # Only transition if currently in radial sampling phase
        if group['phase'] != 'radial_sampling':
            return False
        
        try:
            # Select the M best points from radial sampling results
            best_M_points = self._select_best_points(group_id)
            
            # Store best points in group
            group['best_M_points'] = best_M_points
            
            # Assign particles to best points
            self._assign_particles_to_points(group_id)
            
            # Change phase to hill climbing
            group['phase'] = 'hill_climbing'
            
            # Reset remaining iterations counter (starts counting down from here)
            group['remaining_iterations'] = self.hill_climber_config['hill_climber_lifetime']
            
            # Log transition
            ocean_hit_pct = group['ocean_hit_percentage']
            threshold_pct = self.hill_climber_config['ocean_hit_threshold'] * 100
            best_fitness = min(fitness_values) if fitness_values else np.inf
            
            self.log_message(
                f"ğŸ¯ Phase transition - Group {group_id}: radial_sampling â†’ hill_climbing "
                f"(ocean hits: {ocean_hit_pct:.1f}% â‰¥ {threshold_pct:.1f}%, "
                f"best fitness: {best_fitness:.6e}, {len(best_M_points)} best points selected)",
                emoji="ğŸ¯"
            )
            
            return True
            
        except Exception as e:
            self.log_message(f"âš ï¸ Error transitioning group {group_id} to hill climbing: {e}", emoji="âš ï¸")
            return False

    def _select_best_points(self, group_id):
        """Select the M best points from radial sampling results
        
        Parameters
        ----------
        group_id : str
            ID of the hill climber group
            
        Returns
        -------
        list of np.ndarray
            List of the M best points from radial sampling
        """
        if group_id not in self.active_hill_climber_groups:
            return []
        
        group = self.active_hill_climber_groups[group_id]
        climber_ids = group['climber_ids']
        M = len(climber_ids)  # Use all available climbers
        
        # Collect all sampled points and their fitness values
        sampled_points = []
        fitness_values = []
        
        for climber_id in climber_ids:
            climber = self.hill_climber_particles[climber_id]
            sampled_points.append(climber['local_best'])
            fitness_values.append(climber['local_best_fitness'])
        
        # Sort by fitness (best first)
        sorted_indices = np.argsort(fitness_values)
        
        # Select the M best points
        best_M_points = []
        for i in range(min(M, len(sorted_indices))):
            idx = sorted_indices[i]
            best_M_points.append(sampled_points[idx])
        
        return best_M_points

    def _assign_particles_to_points(self, group_id):
        """Assign hill climber particles to the best points for local optimization
        
        Parameters
        ----------
        group_id : str
            ID of the hill climber group
        """
        if group_id not in self.active_hill_climber_groups:
            return
        
        group = self.active_hill_climber_groups[group_id]
        best_points = group['best_M_points']
        climber_ids = group['climber_ids']
        
        # Assign each particle to a best point
        for i, climber_id in enumerate(climber_ids):
            if i < len(best_points):
                # Assign to corresponding best point
                assigned_point = best_points[i]
            else:
                # If more particles than best points, assign to random best point
                assigned_point = best_points[i % len(best_points)]
            
            # Update hill climber particle
            climber = self.hill_climber_particles[climber_id]
            climber['assigned_point'] = assigned_point.copy()
            climber['position'] = assigned_point.copy()
            climber['local_best'] = assigned_point.copy()
            # Keep the fitness from radial sampling as starting point

    def _perform_hill_climbing(self, group_id, objective_func, **kwargs):
        """Perform gradient-based local optimization for hill climber particles
        
        Parameters
        ----------
        group_id : str
            ID of the hill climber group
        objective_func : callable
            Objective function for evaluation
        **kwargs : dict
            Additional arguments for objective function
            
        Returns
        -------
        bool
            True if hill climbing was performed successfully, False otherwise
        """
        if group_id not in self.active_hill_climber_groups:
            return False
        
        group = self.active_hill_climber_groups[group_id]
        
        # Only perform hill climbing if in the correct phase
        if group['phase'] != 'hill_climbing':
            return False
        
        try:
            climber_ids = group['climber_ids']
            
            # Perform gradient-based optimization for each hill climber particle
            for climber_id in climber_ids:
                climber = self.hill_climber_particles[climber_id]
                current_position = climber['position']
                current_best_fitness = climber['local_best_fitness']
                
                # Simple gradient-based hill climbing using finite differences
                improved_position, improved_fitness = self._gradient_based_step(
                    current_position, current_best_fitness, objective_func, **kwargs
                )
                
                # Update particle if improvement found
                if improved_fitness < current_best_fitness:
                    climber['position'] = improved_position
                    climber['local_best'] = improved_position.copy()
                    climber['local_best_fitness'] = improved_fitness
                    
                    # Update group best if this is better
                    if improved_fitness < group['best_fitness']:
                        group['best_fitness'] = improved_fitness
                        group['best_point'] = improved_position.copy()
                        
                        # Log improvement
                        self.log_message(
                            f"ğŸ”ï¸ Hill climbing improvement - Group {group_id}: "
                            f"new best fitness {improved_fitness:.6e}",
                            emoji="ğŸ”ï¸"
                        )
            
            # Decrement remaining iterations after hill climbing step
            group['remaining_iterations'] -= 1
            
            return True
            
        except Exception as e:
            self.log_message(f"âš ï¸ Error in hill climbing for group {group_id}: {e}", emoji="âš ï¸")
            return False

    def _gradient_based_step(self, position, current_fitness, objective_func, **kwargs):
        """Perform a single gradient-based optimization step using finite differences
        
        Parameters
        ----------
        position : np.ndarray
            Current position
        current_fitness : float
            Current fitness value
        objective_func : callable
            Objective function for evaluation
        **kwargs : dict
            Additional arguments for objective function
            
        Returns
        -------
        tuple
            (improved_position, improved_fitness) if improvement found,
            otherwise (position, current_fitness)
        """
        try:
            # Step size for finite differences
            step_size = 1e-6
            
            # Calculate gradient using finite differences
            gradient = np.zeros(self.dimensions)
            
            for dim in range(self.dimensions):
                # Forward step
                pos_forward = position.copy()
                pos_forward[dim] += step_size
                
                # Backward step
                pos_backward = position.copy()
                pos_backward[dim] -= step_size
                
                # Ensure positions are within bounds
                if self.bounds is not None:
                    lower_bounds, upper_bounds = self.bounds
                    pos_forward = np.clip(pos_forward, lower_bounds, upper_bounds)
                    pos_backward = np.clip(pos_backward, lower_bounds, upper_bounds)
                
                # Evaluate fitness at forward and backward positions
                temp_swarm_forward = type('TempSwarm', (), {})()
                temp_swarm_forward.position = pos_forward.reshape(1, -1)
                fitness_forward = compute_objective_function(temp_swarm_forward, objective_func, pool=None, **kwargs)[0]
                
                temp_swarm_backward = type('TempSwarm', (), {})()
                temp_swarm_backward.position = pos_backward.reshape(1, -1)
                fitness_backward = compute_objective_function(temp_swarm_backward, objective_func, pool=None, **kwargs)[0]
                
                # Calculate gradient component
                gradient[dim] = (fitness_forward - fitness_backward) / (2 * step_size)
            
            # Adaptive step size based on gradient magnitude
            gradient_magnitude = np.linalg.norm(gradient)
            if gradient_magnitude > 0:
                # Normalize gradient and apply adaptive step
                if self.bounds is not None:
                    lower_bounds, upper_bounds = self.bounds
                    parameter_ranges = upper_bounds - lower_bounds
                    adaptive_step = 0.01 * np.mean(parameter_ranges)  # 1% of average parameter range
                else:
                    adaptive_step = 0.01  # Default step size
                
                # Move in opposite direction of gradient (minimize)
                new_position = position - (adaptive_step / gradient_magnitude) * gradient
                
                # Ensure new position is within bounds
                if self.bounds is not None:
                    lower_bounds, upper_bounds = self.bounds
                    new_position = np.clip(new_position, lower_bounds, upper_bounds)
                
                # Evaluate new position
                temp_swarm = type('TempSwarm', (), {})()
                temp_swarm.position = new_position.reshape(1, -1)
                new_fitness = compute_objective_function(temp_swarm, objective_func, pool=None, **kwargs)[0]
                
                # Return improvement if found
                if new_fitness < current_fitness:
                    return new_position, new_fitness
            
            # No improvement found
            return position, current_fitness
            
        except Exception as e:
            # Return original position if error occurs
            return position, current_fitness

    def _process_hill_climber_groups(self, iteration, objective_func, **kwargs):
        """Process all active hill climber groups for the current iteration
        
        Parameters
        ----------
        iteration : int
            Current iteration number
        objective_func : callable
            Objective function for evaluation
        **kwargs : dict
            Additional arguments for objective function
        """
        if not self.hill_climber_config['enable_hill_climbers']:
            return
        
        # Get list of group IDs to avoid modification during iteration
        group_ids = list(self.active_hill_climber_groups.keys())
        
        for group_id in group_ids:
            if group_id not in self.active_hill_climber_groups:
                continue  # Group may have been terminated
            
            group = self.active_hill_climber_groups[group_id]
            
            if group['phase'] == 'radial_sampling':
                # Perform radial sampling
                self._perform_radial_sampling(group_id, objective_func, **kwargs)
                
            elif group['phase'] == 'hill_climbing':
                # Perform hill climbing
                self._perform_hill_climbing(group_id, objective_func, **kwargs)
                
                # Check if group should be terminated (lifetime expired)
                if group['remaining_iterations'] <= 0:
                    self._terminate_hill_climber_group(group_id, iteration)

    def _terminate_hill_climber_group(self, group_id, iteration):
        """Terminate a hill climber group and clean up resources
        
        Parameters
        ----------
        group_id : str
            ID of the hill climber group to terminate
        iteration : int
            Current iteration number
        """
        if group_id not in self.active_hill_climber_groups:
            return
        
        try:
            group = self.active_hill_climber_groups[group_id]
            climber_ids = group['climber_ids']
            
            # Log termination
            final_best_fitness = group['best_fitness']
            spawner_id = group['spawner_id']
            
            self.log_message(
                f"âš°ï¸ Hill climber group terminated - Group {group_id}: "
                f"spawner #{spawner_id}, final best fitness: {final_best_fitness:.6e}, "
                f"lifetime expired at iteration {iteration}",
                emoji="âš°ï¸"
            )
            
            # Clean up hill climber particles
            for climber_id in climber_ids:
                if climber_id in self.hill_climber_particles:
                    del self.hill_climber_particles[climber_id]
            
            # Remove group from active groups
            del self.active_hill_climber_groups[group_id]
            
        except Exception as e:
            self.log_message(f"âš ï¸ Error terminating hill climber group {group_id}: {e}", emoji="âš ï¸")
